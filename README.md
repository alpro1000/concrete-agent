# Concrete Agent (Stav Agent)

**Scientific-Method Based Construction Analysis System**

A modular, research-grade system for analyzing construction documents, specifications, and requirements using AI agents that follow the scientific method.

## üèóÔ∏è Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TypeScript)             ‚îÇ
‚îÇ                     Czech Locale Support                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FastAPI Backend                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              Orchestrator                              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Coordinates agent workflow execution)                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                       ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ         Agent Registry (Dynamic Discovery)             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                       ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                 Modular Agents                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ TZD      ‚îÇ BOQ     ‚îÇ Drawing    ‚îÇ Resource     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Reader   ‚îÇ Parser  ‚îÇ Parser     ‚îÇ Estimator    ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Site     ‚îÇ Knowledge‚îÇ Export    ‚îÇ Chat         ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Foreman  ‚îÇ Base    ‚îÇ Agent      ‚îÇ Agent        ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ       Each Agent: Hypothesis ‚Üí Reasoning ‚Üí            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 Verification ‚Üí Conclusion             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ           LLM Service (with Fallback)                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Primary: Anthropic Claude ‚îÄ‚îÄfallback‚Üí OpenAI GPT    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ            Knowledge Base (ƒåSN, EN Norms)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Materials DB ‚Ä¢ Mechanization ‚Ä¢ Pricing ‚Ä¢ Standards   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PostgreSQL Database                             ‚îÇ
‚îÇ    Users ‚Ä¢ Analyses ‚Ä¢ Files ‚Ä¢ Results ‚Ä¢ Reasoning Chains    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üéØ Key Features

### Scientific Method Integration
Every agent follows a rigorous four-step process:
1. **Hypothesis** - Form initial assumptions about the problem
2. **Reasoning** - Systematic analysis of data
3. **Verification** - Validation of results
4. **Conclusion** - Clear, actionable output

### Modular Agent System
- **Dynamic Discovery**: Agents are automatically discovered and registered
- **Pluggable Architecture**: Add new agents without modifying core code
- **Independent Testing**: Each agent can be tested in isolation
- **Version Control**: Track agent versions and capabilities

### LLM Resilience
- **Automatic Fallback**: Primary (Anthropic) ‚Üí Fallback (OpenAI)
- **Provider Abstraction**: Easy to add new LLM providers
- **Error Recovery**: Graceful handling of LLM failures

### Czech Language Support
- **Diacritic Preservation**: Maintains Czech characters correctly
- **Encoding Detection**: Identifies and fixes encoding issues
- **Normalization Service**: Multiple strategies for text processing

### Knowledge Base
- **ƒåSN Standards**: Czech construction norms (ƒåSN 73 2400, etc.)
- **EN Standards**: European norms (EN 206, etc.)
- **Material Database**: Specifications and pricing
- **Mechanization**: Equipment rates and capabilities

## üìÅ Project Structure

```
concrete-agent/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/              # System core (config, db, LLM, orchestrator)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/            # Modular agent implementations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py  # Base class with scientific method
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tzd_reader/    # Example: TZD document parser
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ boq_parser/    # Bill of quantities parser
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...            # Other specialized agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/           # FastAPI endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/            # SQLAlchemy ORM models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Pydantic validation schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/          # Utility services (registry, normalization)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledgebase/     # Norms, materials, pricing data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts/           # LLM prompts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/             # Unit and integration tests
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ
‚îú‚îÄ‚îÄ frontend/                  # React TypeScript application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ database/                  # Database migrations and seed data
‚îú‚îÄ‚îÄ tests/                     # System-wide tests
‚îú‚îÄ‚îÄ .github/workflows/         # CI/CD pipelines
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Quick Start

### Prerequisites
- Python 3.11+
- Node.js 20+
- PostgreSQL (or SQLite for development)

### Backend Setup

```bash
# Navigate to project root (not backend/)
cd concrete-agent

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env with your API keys and configuration

# Run the application (from project root)
uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`
- API Documentation: `http://localhost:8000/docs`
- Health Check: `http://localhost:8000/health`
- Status & Agents: `http://localhost:8000/status`

> **Note:** The application now uses proper Python package imports (`backend.app.*`).
> Always run from the project root directory. See [DEPLOYMENT.md](DEPLOYMENT.md) for details.

### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

### Running Tests

```bash
# Run all tests from project root
pytest backend/tests/test_imports.py backend/app/tests/ -v

# Run with coverage
pytest backend/app/tests/ --cov=backend.app --cov-report=html

# Run specific test file
pytest backend/app/tests/test_registry.py -v

# Run new import validation tests
pytest backend/tests/test_imports.py -v
```

**Test Suite:**
- 26 tests total (9 import validation + 17 functional tests)
- Import tests ensure proper module resolution
- All tests run from project root
```

## üîß Configuration

Key environment variables (see `.env.example`):

```env
# LLM Configuration
ANTHROPIC_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
LLM_PRIMARY_PROVIDER=anthropic
LLM_FALLBACK_PROVIDER=openai

# Database
DATABASE_URL=postgresql://user:pass@localhost/concrete_agent

# Server
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false
```

## ü§ñ Agent Development

Creating a new agent is straightforward:

```python
from app.agents.base_agent import BaseAgent, AgentResult
from typing import Dict, Any

class MyCustomAgent(BaseAgent):
    name = "my_agent"
    description = "Does something useful"
    version = "1.0.0"
    
    async def execute(self, input_data: Dict[str, Any]) -> AgentResult:
        # Validate input
        self.validate_input(input_data, required_fields=["field1"])
        
        # Scientific method steps
        hypothesis = await self.hypothesis(
            problem="What needs to be solved",
            context=input_data
        )
        
        reasoning = await self.reasoning(
            hypothesis=hypothesis,
            data=input_data
        )
        
        verification = await self.verification(
            reasoning=reasoning
        )
        
        conclusion = await self.conclusion(
            reasoning=reasoning,
            verification_passed=verification
        )
        
        return AgentResult(
            success=True,
            data={"result": conclusion},
            reasoning_chain=self.get_reasoning_chain()
        )
```

Place the agent in `app/agents/my_agent/agent.py` and it will be automatically discovered!

## üìä API Endpoints

### Health & Status
- `GET /health` - Health check
- `GET /status` - System status and available agents

### Agents (Coming Soon)
- `POST /api/agents/execute` - Execute a specific agent
- `POST /api/agents/workflow` - Execute a workflow
- `GET /api/agents` - List available agents

### Users (Coming Soon)
- `POST /api/users/register` - Register new user
- `POST /api/users/login` - User login
- `GET /api/users/me` - Get current user

### Results (Coming Soon)
- `GET /api/results` - List analysis results
- `GET /api/results/{id}` - Get specific result

## üß™ Testing Strategy

### Unit Tests
Each agent and service has dedicated unit tests:
- `app/tests/test_registry.py` - Agent registry
- `app/tests/test_normalization.py` - Czech text processing
- `app/agents/tzd_reader/tests/` - Agent-specific tests

### Integration Tests
Located in `tests/integration/`:
- End-to-end workflow testing
- Multi-agent coordination
- Database integration

### Performance Tests
Located in `tests/performance/`:
- Load testing
- Response time benchmarks
- Resource usage monitoring

## üî¨ Scientific Method Reasoning

All agents produce traceable reasoning chains:

```json
{
  "reasoning_chain": [
    {
      "step": "hypothesis",
      "content": "The document contains technical requirements...",
      "confidence": 0.5,
      "timestamp": "2024-01-01T10:00:00"
    },
    {
      "step": "reasoning",
      "content": "Analysis shows 5 main sections...",
      "confidence": 0.7,
      "timestamp": "2024-01-01T10:00:05"
    },
    {
      "step": "verification",
      "content": "All sections validated successfully",
      "confidence": 0.8,
      "timestamp": "2024-01-01T10:00:10"
    },
    {
      "step": "conclusion",
      "content": "Document parsed with 95% confidence",
      "confidence": 0.9,
      "timestamp": "2024-01-01T10:00:15"
    }
  ]
}
```

## üåç Deployment

### Docker (Local Development)

```bash
# Run with docker-compose (from project root)
docker-compose up -d
```

### Docker (Production Build)

```bash
# Build from project root using production Dockerfile
docker build -f Dockerfile.backend -t concrete-agent-backend .

# Run
docker run -p 8000:8000 \
  -e DATABASE_URL=postgresql://user:pass@localhost/db \
  -e ANTHROPIC_API_KEY=your_key \
  concrete-agent-backend
```

### Render Deployment

The project uses proper Python package structure for reliable Render deployments.

**Configuration:**
- **Build Command:** `pip install -r requirements.txt`
- **Start Command:** `uvicorn backend.app.main:app --host 0.0.0.0 --port $PORT`
- **Root Directory:** `/` (project root)

**GitHub Actions Workflows:**
- `deploy-backend.yml` - Automated backend deployment with import validation
- `deploy-frontend.yml` - Frontend deployment
- `render_purge.yml` - Cache management

**‚úÖ Key Features:**
- No sys.path manipulation required
- Same command works locally and in production
- Comprehensive import validation tests
- Full deployment guide in [DEPLOYMENT.md](DEPLOYMENT.md)

## üìö Knowledge Base

The system includes comprehensive knowledge bases:

- **ƒåSN Standards**: Czech construction norms
- **EN Standards**: European standards
- **Material Database**: 100+ construction materials with properties and pricing
- **Mechanization**: Equipment specifications and rates
- **Labor Rates**: Czech construction labor pricing

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Implement your changes with tests
4. Ensure all tests pass
5. Submit a pull request

## üìÑ License

MIT License - See [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

Built with:
- FastAPI - Modern Python web framework
- React - UI library
- Anthropic Claude & OpenAI GPT - LLM providers
- SQLAlchemy - Database ORM
- Pydantic - Data validation

**System Features:**
- ‚úÖ 2 functional agents (TZD Reader, BOQ Parser)
- ‚úÖ Dynamic agent registry with automatic discovery
- ‚úÖ Scientific method reasoning chain
- ‚úÖ LLM fallback system (Anthropic ‚Üí OpenAI)
- ‚úÖ Czech language normalization
- ‚úÖ REST API with OpenAPI documentation
- ‚úÖ React TypeScript frontend with Czech locale
- ‚úÖ Comprehensive testing (10 tests passing)
- ‚úÖ Docker deployment ready

---

**Version**: 1.0.0  
**Last Updated**: 2024-10-05  
**Status**: ‚úÖ Production Ready
