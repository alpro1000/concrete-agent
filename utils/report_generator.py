"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ —Å –æ–±—ä–µ–º–∞–º–∏ –±–µ—Ç–æ–Ω–∞
utils/report_generator.py
"""

import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)

class ConcreteReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –ø–æ –∞–Ω–∞–ª–∏–∑—É –±–µ—Ç–æ–Ω–∞ —Å –æ–±—ä–µ–º–∞–º–∏"""
    
    def __init__(self, language: str = 'cz'):
        self.language = language.lower()
        
        # –°–ª–æ–≤–∞—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        self.translations = {
            'cz': {
                'title': 'ANAL√ùZA BETONU A OBJEM≈Æ',
                'project_overview': 'P≈òEHLED PROJEKTU',
                'concrete_grades': 'NALEZEN√â T≈ò√çDY BETONU',
                'volume_summary': 'SOUHRN OBJEM≈Æ',
                'detailed_analysis': 'DETAILN√ç ANAL√ùZA',
                'technical_specs': 'TECHNICK√â PARAMETRY',
                'total_volume': 'Celkov√Ω objem',
                'applications': 'Pou≈æit√≠',
                'exposure_classes': 'T≈ô√≠dy prost≈ôed√≠',
                'construction_element': 'Konstrukƒçn√≠ prvek',
                'confidence': 'Spolehlivost',
                'source_documents': 'Zdrojov√© dokumenty',
                'processing_stats': 'Statistiky zpracov√°n√≠',
                'recommendations': 'DOPORUƒåEN√ç',
                'cubic_meters': 'm¬≥',
                'square_meters': 'm¬≤',
                'thickness': 'Tlou≈°≈•ka',
                'no_volume_data': 'Objem nezji≈°tƒõn',
                'total': 'Celkem',
                'element': 'Prvek',
                'volume': 'Objem',
                'method': 'Metoda',
            },
            'en': {
                'title': 'CONCRETE AND VOLUME ANALYSIS',
                'project_overview': 'PROJECT OVERVIEW',
                'concrete_grades': 'IDENTIFIED CONCRETE GRADES',
                'volume_summary': 'VOLUME SUMMARY',
                'detailed_analysis': 'DETAILED ANALYSIS',
                'technical_specs': 'TECHNICAL SPECIFICATIONS',
                'total_volume': 'Total Volume',
                'applications': 'Applications',
                'exposure_classes': 'Exposure Classes',
                'construction_element': 'Construction Element',
                'confidence': 'Confidence',
                'source_documents': 'Source Documents',
                'processing_stats': 'Processing Statistics',
                'recommendations': 'RECOMMENDATIONS',
                'cubic_meters': 'm¬≥',
                'square_meters': 'm¬≤',
                'thickness': 'Thickness',
                'no_volume_data': 'Volume not determined',
                'total': 'Total',
                'element': 'Element',
                'volume': 'Volume',
                'method': 'Method',
            },
            'ru': {
                'title': '–ê–ù–ê–õ–ò–ó –ë–ï–¢–û–ù–ê –ò –û–ë–™–ï–ú–û–í',
                'project_overview': '–û–ë–ó–û–† –ü–†–û–ï–ö–¢–ê',
                'concrete_grades': '–ù–ê–ô–î–ï–ù–ù–´–ï –ú–ê–†–ö–ò –ë–ï–¢–û–ù–ê',
                'volume_summary': '–°–í–û–î–ö–ê –û–ë–™–ï–ú–û–í',
                'detailed_analysis': '–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó',
                'technical_specs': '–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò',
                'total_volume': '–û–±—â–∏–π –æ–±—ä–µ–º',
                'applications': '–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ',
                'exposure_classes': '–ö–ª–∞—Å—Å—ã –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è',
                'construction_element': '–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç',
                'confidence': '–î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å',
                'source_documents': '–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã',
                'processing_stats': '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏',
                'recommendations': '–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò',
                'cubic_meters': '–º¬≥',
                'square_meters': '–º¬≤',
                'thickness': '–¢–æ–ª—â–∏–Ω–∞',
                'no_volume_data': '–û–±—ä–µ–º –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω',
                'total': '–ò—Ç–æ–≥–æ',
                'element': '–≠–ª–µ–º–µ–Ω—Ç',
                'volume': '–û–±—ä–µ–º',
                'method': '–ú–µ—Ç–æ–¥',
            }
        }

    def t(self, key: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –ø–æ –∫–ª—é—á—É"""
        return self.translations.get(self.language, self.translations['cz']).get(key, key)

    def generate_markdown_report(self, analysis_result: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown"""
        
        report_lines = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        report_lines.extend([
            f"# {self.t('title')}",
            "",
            f"*–°–æ–∑–¥–∞–Ω: {datetime.now().strftime('%d.%m.%Y %H:%M')}*",
            "",
            "---",
            ""
        ])
        
        # –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞
        report_lines.extend(self._generate_project_overview(analysis_result))
        
        # –°–≤–æ–¥–∫–∞ –æ–±—ä–µ–º–æ–≤
        if self._has_volume_data(analysis_result):
            report_lines.extend(self._generate_volume_summary(analysis_result))
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –º–∞—Ä–∫–∞–º
        report_lines.extend(self._generate_detailed_analysis(analysis_result))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        report_lines.extend(self._generate_processing_stats(analysis_result))
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report_lines.extend(self._generate_recommendations(analysis_result))
        
        return "\n".join(report_lines)

    def _generate_project_overview(self, data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞"""
        lines = [
            f"## {self.t('project_overview')}",
            ""
        ]
        
        # –î–æ–∫—É–º–µ–Ω—Ç—ã
        docs = data.get('processed_documents', [])
        if docs:
            lines.extend([
                f"**{self.t('source_documents')}:**",
            ])
            
            total_chars = 0
            for doc in docs:
                if isinstance(doc, dict) and 'file' in doc:
                    chars = doc.get('text_length', 0)
                    total_chars += chars
                    status = "" if chars > 0 else " ‚ö†Ô∏è"
                    lines.append(f"- `{doc['file']}` ({chars:,} —Å–∏–º–≤–æ–ª–æ–≤){status}")
            
            lines.extend([
                "",
                f"**–û–±—â–∏–π –æ–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞:** {total_chars:,} —Å–∏–º–≤–æ–ª–æ–≤",
                ""
            ])
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        concrete_count = len(data.get('concrete_summary', []))
        volume_info = data.get('volume_analysis', {})
        
        lines.extend([
            f"**–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**",
            f"- –ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–æ–∫ –±–µ—Ç–æ–Ω–∞: {concrete_count}",
            f"- –ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {data.get('analysis_method', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}",
        ])
        
        if volume_info:
            lines.append(f"- –ü–æ–∑–∏—Ü–∏–π —Å –æ–±—ä–µ–º–∞–º–∏: {volume_info.get('total_entries', 0)}")
            lines.append(f"- –ú–∞—Ä–æ–∫ —Å –æ–±—ä–µ–º–∞–º–∏: {volume_info.get('grades_with_volumes', 0)}")
        
        # –ß–µ—à—Å–∫–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        czech_stats = data.get('czech_preprocessing', {})
        if czech_stats and czech_stats.get('diacritic_fixes', 0) > 0:
            lines.extend([
                "",
                f"**–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—à—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:**",
                f"- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {czech_stats['diacritic_fixes']:,}",
            ])
        
        lines.extend(["", "---", ""])
        return lines

    def _generate_volume_summary(self, data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –æ–±—ä–µ–º–∞–º"""
        lines = [
            f"## {self.t('volume_summary')}",
            ""
        ]
        
        # –¢–∞–±–ª–∏—Ü–∞ –æ–±—â–∏—Ö –æ–±—ä–µ–º–æ–≤
        concrete_summary = data.get('concrete_summary', [])
        
        if concrete_summary:
            lines.extend([
                "| –ú–∞—Ä–∫–∞ –±–µ—Ç–æ–Ω–∞ | –û–±—â–∏–π –æ–±—ä–µ–º | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è | –°—Ç–∞—Ç—É—Å |",
                "|-------------|-------------|------------|--------|"
            ])
            
            total_volume = 0
            for item in concrete_summary:
                grade = item.get('grade', 'N/A')
                volume = item.get('total_volume_m3', 0)
                apps = item.get('volume_applications', [])
                has_volume = item.get('has_volume_data', False)
                
                volume_str = f"{volume:.2f} {self.t('cubic_meters')}" if volume > 0 else self.t('no_volume_data')
                apps_str = f"{len(apps)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤" if apps else "‚Äî"
                status = "‚úÖ" if has_volume else "‚ö†Ô∏è"
                
                lines.append(f"| **{grade}** | {volume_str} | {apps_str} | {status} |")
                
                if volume > 0:
                    total_volume += volume
            
            lines.extend([
                "",
                f"**{self.t('total')}:** {total_volume:.2f} {self.t('cubic_meters')}",
                "",
                "---",
                ""
            ])
        
        return lines

    def _generate_detailed_analysis(self, data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–∞–∂–¥–æ–π –º–∞—Ä–∫–µ"""
        lines = [
            f"## {self.t('detailed_analysis')}",
            ""
        ]
        
        concrete_summary = data.get('concrete_summary', [])
        
        for i, item in enumerate(concrete_summary, 1):
            grade = item.get('grade', 'N/A')
            location = item.get('location', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')
            confidence = item.get('confidence', 0)
            context = item.get('context', '')
            
            lines.extend([
                f"### {i}. {grade}",
                ""
            ])
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            lines.extend([
                f"**{self.t('construction_element')}:** {location}",
                f"**{self.t('confidence')}:** {confidence:.0%}",
                f"**{self.t('method')}:** {item.get('method', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}",
                ""
            ])
            
            # –û–±—ä–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            volume_apps = item.get('volume_applications', [])
            total_vol = item.get('total_volume_m3', 0)
            
            if volume_apps:
                lines.extend([
                    f"**{self.t('volume_summary')}:**",
                    f"- {self.t('total_volume')}: {total_vol:.2f} {self.t('cubic_meters')}",
                    ""
                ])
                
                for app in volume_apps:
                    element = app.get('element', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    vol = app.get('volume_m3', 0)
                    count = app.get('entries_count', 0)
                    lines.append(f"  - {element}: {vol:.2f} {self.t('cubic_meters')} ({count} –ø–æ–∑–∏—Ü–∏–π)")
                
                lines.append("")
            else:
                lines.extend([
                    f"**{self.t('volume')}:** {self.t('no_volume_data')}",
                    ""
                ])
            
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç
            if context:
                lines.extend([
                    "**–ö–æ–Ω—Ç–µ–∫—Å—Ç:**",
                    f"> {context[:200]}{'...' if len(context) > 200 else ''}",
                    ""
                ])
            
            lines.extend(["---", ""])
        
        return lines

    def _generate_processing_stats(self, data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        lines = [
            f"## {self.t('processing_stats')}",
            ""
        ]
        
        # Claude –∞–Ω–∞–ª–∏–∑
        claude_stats = data.get('claude_analysis', {})
        if claude_stats:
            lines.extend([
                "**Claude AI –∞–Ω–∞–ª–∏–∑:**",
                f"- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {claude_stats.get('tokens_used', 0):,}",
                f"- –°—Ç–∞—Ç—É—Å: {'‚úÖ' if claude_stats.get('success') else '‚ùå'}",
                ""
            ])
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.extend([
            "**–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**",
            f"- –î–æ–ø—É—Å—Ç–∏–º—ã—Ö –º–∞—Ä–æ–∫ –≤ –±–∞–∑–µ: {data.get('allowed_grades_count', 0)}",
            f"- –í–µ—Ä—Å–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {data.get('knowledge_base_version', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}",
            f"- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {data.get('processing_time', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}",
            ""
        ])
        
        # –û–±—ä–µ–º–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        volume_stats = data.get('volume_analysis', {})
        if volume_stats:
            lines.extend([
                "**–ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–æ–≤:**",
                f"- –í—Å–µ–≥–æ –ø–æ–∑–∏—Ü–∏–π —Å –æ–±—ä–µ–º–∞–º–∏: {volume_stats.get('total_entries', 0)}",
                f"- –ú–∞—Ä–æ–∫ —Å –æ–±—ä–µ–º–∞–º–∏: {volume_stats.get('grades_with_volumes', 0)}",
                ""
            ])
        
        lines.extend(["---", ""])
        return lines

    def _generate_recommendations(self, data: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        lines = [
            f"## {self.t('recommendations')}",
            ""
        ]
        
        recommendations = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        docs = data.get('processed_documents', [])
        empty_docs = [d for d in docs if isinstance(d, dict) and d.get('text_length', 0) == 0]
        if empty_docs:
            recommendations.append(
                f"**–ü—Ä–æ–±–ª–µ–º—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏:** {len(empty_docs)} —Ñ–∞–π–ª–æ–≤ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏—Å—å. "
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å PDF —Ñ–∞–π–ª–æ–≤."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–æ–≤
        concrete_summary = data.get('concrete_summary', [])
        no_volume = [c for c in concrete_summary if not c.get('has_volume_data', False)]
        if no_volume:
            recommendations.append(
                f"**–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—ä–µ–º—ã:** –¥–ª—è {len(no_volume)} –º–∞—Ä–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—ä–µ–º—ã. "
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–º–µ—Ç—É –∏–ª–∏ v√Ωkaz v√Ωmƒõr."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏
        czech_stats = data.get('czech_preprocessing', {})
        if czech_stats and czech_stats.get('diacritic_fixes', 0) > 1000:
            recommendations.append(
                f"**–ö–∞—á–µ—Å—Ç–≤–æ PDF:** –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ {czech_stats['diacritic_fixes']} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤. "
                f"–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö PDF —Ñ–∞–π–ª–æ–≤."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
        recommendations.append(
            "**–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è:** —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–∞—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç "
            "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º ƒåSN EN 206+A2 –∏ —É—Å–ª–æ–≤–∏—è–º —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏."
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                lines.append(f"{i}. {rec}")
                lines.append("")
        else:
            lines.extend([
                "–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã—è–≤–∏–ª –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º. –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.",
                ""
            ])
        
        return lines

    def _has_volume_data(self, data: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ–±—ä–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return bool(data.get('volume_analysis', {}).get('total_entries', 0) > 0)

    def generate_excel_data(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è Excel —Ç–∞–±–ª–∏—Ü—ã"""
        
        excel_data = {
            'summary': [],
            'details': [],
            'volumes': [],
            'documents': []
        }
        
        # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        concrete_summary = analysis_result.get('concrete_summary', [])
        for item in concrete_summary:
            excel_data['summary'].append({
                '–ú–∞—Ä–∫–∞ –±–µ—Ç–æ–Ω–∞': item.get('grade', ''),
                '–ö–ª–∞—Å—Å –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è': self._extract_exposure_classes(item.get('context', '')),
                '–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç': item.get('location', ''),
                '–û–±—â–∏–π –æ–±—ä–µ–º (–º¬≥)': item.get('total_volume_m3', 0),
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–π': len(item.get('volume_applications', [])),
                '–î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å': f"{item.get('confidence', 0):.0%}",
                '–ï—Å—Ç—å –æ–±—ä–µ–º—ã': '–î–∞' if item.get('has_volume_data', False) else '–ù–µ—Ç'
            })
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        for item in concrete_summary:
            volume_apps = item.get('volume_applications', [])
            if volume_apps:
                for app in volume_apps:
                    excel_data['details'].append({
                        '–ú–∞—Ä–∫–∞ –±–µ—Ç–æ–Ω–∞': item.get('grade', ''),
                        '–≠–ª–µ–º–µ–Ω—Ç': app.get('element', ''),
                        '–û–±—ä–µ–º (–º¬≥)': app.get('volume_m3', 0),
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ü–∏–π': app.get('entries_count', 0),
                        '–ò—Å—Ç–æ—á–Ω–∏–∫': item.get('method', ''),
                        '–ö–æ–Ω—Ç–µ–∫—Å—Ç': item.get('context', '')[:100] + '...' if len(item.get('context', '')) > 100 else item.get('context', '')
                    })
            else:
                excel_data['details'].append({
                    '–ú–∞—Ä–∫–∞ –±–µ—Ç–æ–Ω–∞': item.get('grade', ''),
                    '–≠–ª–µ–º–µ–Ω—Ç': item.get('location', ''),
                    '–û–±—ä–µ–º (–º¬≥)': 0,
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ü–∏–π': 0,
                    '–ò—Å—Ç–æ—á–Ω–∏–∫': item.get('method', ''),
                    '–ö–æ–Ω—Ç–µ–∫—Å—Ç': item.get('context', '')[:100] + '...' if len(item.get('context', '')) > 100 else item.get('context', '')
                })
        
        # –î–æ–∫—É–º–µ–Ω—Ç—ã
        docs = analysis_result.get('processed_documents', [])
        for doc in docs:
            if isinstance(doc, dict):
                excel_data['documents'].append({
                    '–§–∞–π–ª': doc.get('file', ''),
                    '–¢–∏–ø': doc.get('type', ''),
                    '–†–∞–∑–º–µ—Ä (—Å–∏–º–≤–æ–ª–æ–≤)': doc.get('text_length', 0),
                    '–°—Ç–∞—Ç—É—Å': '–û–±—Ä–∞–±–æ—Ç–∞–Ω' if doc.get('text_length', 0) > 0 else '–û—à–∏–±–∫–∞'
                })
        
        return excel_data

    def _extract_exposure_classes(self, context: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª–∞—Å—Å—ã –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        classes = []
        for match in re.finditer(r'\b[XO][CDFASM]?\d*\b', context):
            classes.append(match.group())
        return ', '.join(classes) if classes else ''

    def save_markdown_report(self, analysis_result: Dict[str, Any], output_path: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –≤ Markdown —Ñ–∞–π–ª"""
        try:
            report_content = self.generate_markdown_report(analysis_result)
            
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            logger.info(f"üìÑ Markdown –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
            return False

    def save_json_data(self, analysis_result: Dict[str, Any], output_path: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            excel_data = self.generate_excel_data(analysis_result)
            
            output_data = {
                'analysis_result': analysis_result,
                'excel_data': excel_data,
                'generated_at': datetime.now().isoformat(),
                'language': self.language
            }
            
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üìä JSON –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON: {e}")
            return False


# Singleton instance
_report_generator = None

def get_report_generator(language: str = 'cz') -> ConcreteReportGenerator:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤"""
    global _report_generator
    if _report_generator is None or _report_generator.language != language.lower():
        _report_generator = ConcreteReportGenerator(language)
        logger.info(f"üìã Report generator initialized (language: {language})")
    return _report_generator


def test_report_generator():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤"""
    generator = get_report_generator('cz')
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_data = {
        'concrete_summary': [
            {
                'grade': 'C25/30',
                'location': 'vrtan√© piloty (drilled piles)',
                'context': 'Zalo≈æen√≠ zdi bude provedeno z velkopr≈Ømƒõrov√Ωch vrtan√Ωch pilot betonu t≈ô√≠dy C25/30 ‚Äì XA1, XC2.',
                'confidence': 0.95,
                'method': 'regex_enhanced_czech',
                'total_volume_m3': 85.25,
                'volume_applications': [
                    {'element': 'piloty', 'volume_m3': 85.25, 'entries_count': 3}
                ],
                'has_volume_data': True
            }
        ],
        'analysis_method': 'hybrid_enhanced_czech',
        'czech_preprocessing': {'diacritic_fixes': 2137},
        'processed_documents': [
            {'file': 'test.pdf', 'type': 'Document', 'text_length': 75000}
        ],
        'volume_analysis': {
            'total_entries': 5,
            'grades_with_volumes': 2
        }
    }
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = generator.generate_markdown_report(test_data)
    
    print("üß™ TESTING REPORT GENERATOR")
    print("=" * 50)
    print(report[:500] + "...")
    
    return report


if __name__ == "__main__":
    test_report_generator()
