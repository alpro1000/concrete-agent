# routers/analyze_tov.py
"""
TOV Analysis Router
Handles TOV (Ð¢Ñ€ÑƒÐ´-ÐžÐ±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ-ÐœÐ°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ñ‹) resource planning and scheduling
"""
from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse, Response
from typing import List, Optional, Dict, Any
import tempfile
import os
import shutil
import logging
from config.settings import settings

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/tov")
async def analyze_tov(
    docs: List[UploadFile] = File(default=[], description="ÐŸÑ€Ð¾ÐµÐºÑ‚Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹"),
    smeta: Optional[UploadFile] = File(default=None, description="Ð¤Ð°Ð¹Ð» ÑÐ¼ÐµÑ‚Ñ‹ (XLSX, CSV, XML)"),
    project_name: str = Form("TOV Analysis Project", description="ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"),
    project_duration_days: Optional[int] = Form(None, description="ÐŸÐ»Ð°Ð½Ð¸Ñ€ÑƒÐµÐ¼Ð°Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð² Ð´Ð½ÑÑ…"),
    use_claude: bool = Form(True, description="Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Claude AI Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"),
    claude_mode: str = Form("enhancement", description="Ð ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Claude: enhancement, full"),
    language: str = Form("cz", description="Ð¯Ð·Ñ‹Ðº Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: cz, en, ru"),
    export_format: str = Form("json", description="Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°: json, csv, excel")
):
    """
    ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð² TOV (Ð¢Ñ€ÑƒÐ´-ÐžÐ±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ-ÐœÐ°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ñ‹)
    
    Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¿Ð»Ð°Ð½ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð² Ñ Ñ€Ð°Ð·Ð±Ð¸Ð²ÐºÐ¾Ð¹ Ð½Ð° Ð·Ð°Ñ…Ð²Ð°Ñ‚ÐºÐ¸, ÐºÐ°Ð»ÐµÐ½Ð´Ð°Ñ€Ð½Ñ‹Ð¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ 
    Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð².
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
    - Ð Ð°Ð±Ð¾Ñ‡Ð¸Ðµ Ð·Ð°Ñ…Ð²Ð°Ñ‚ÐºÐ¸ Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚
    - Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº Ñ€ÐµÑÑƒÑ€ÑÐ°Ð¼ (Ñ‚Ñ€ÑƒÐ´Ð¾Ð²Ñ‹Ðµ, Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ, Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ñ‹)
    - ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    - ÐšÐ°Ð»ÐµÐ½Ð´Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ð»Ð°Ð½ Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð¾Ð¹ Ð“Ð°Ð½Ñ‚Ð°
    """
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Validate inputs
        if not smeta and not docs:
            raise HTTPException(
                status_code=400, 
                detail="âŒ ÐÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÑÐ¼ÐµÑ‚Ñƒ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° TOV"
            )
        
        # Save uploaded files
        uploaded_files = []
        smeta_path = None
        
        # Process documents
        for doc in docs:
            if doc.filename:
                file_path = os.path.join(temp_dir, doc.filename)
                with open(file_path, "wb") as f:
                    f.write(await doc.read())
                uploaded_files.append(file_path)
                logger.info(f"ðŸ“„ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚: {doc.filename}")
        
        # Process estimate file
        if smeta and smeta.filename:
            smeta_path = os.path.join(temp_dir, smeta.filename)
            with open(smeta_path, "wb") as f:
                f.write(await smeta.read())
            logger.info(f"ðŸ“Š Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° ÑÐ¼ÐµÑ‚Ð°: {smeta.filename}")
        
        # Run TOV analysis
        logger.info("ðŸ”„ Ð—Ð°Ð¿ÑƒÑÐº Ð°Ð½Ð°Ð»Ð¸Ð·Ð° TOV...")
        
        tov_result = await _run_tov_analysis(
            doc_paths=uploaded_files,
            smeta_path=smeta_path,
            project_name=project_name,
            project_duration_days=project_duration_days,
            use_claude=use_claude,
            claude_mode=claude_mode,
            language=language
        )
        
        # Export in requested format
        export_data = None
        if export_format == "csv":
            export_data = tov_result.get("csv_export", "")
            return Response(
                content=export_data,
                media_type="text/csv",
                headers={"Content-Disposition": f"attachment; filename=tov_plan_{project_name}.csv"}
            )
        elif export_format == "excel":
            # Placeholder for Excel export
            export_data = tov_result.get("excel_export", None)
            if export_data:
                return Response(
                    content=export_data,
                    media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    headers={"Content-Disposition": f"attachment; filename=tov_plan_{project_name}.xlsx"}
                )
        
        # Default JSON response
        response_data = {
            "status": "success",
            "project_name": project_name,
            "analysis_type": "tov_resource_planning",
            "input_files": {
                "documents": len(uploaded_files),
                "estimate": smeta.filename if smeta else None
            },
            "tov_analysis": tov_result,
            "export_formats": ["json", "csv", "excel"],
            "timestamp": "2025-01-09T12:00:00Z"
        }
        
        return JSONResponse(content=response_data)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° TOV: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð° Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ TOV: {str(e)}"
        )
    finally:
        # Cleanup temp files
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            logger.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹: {e}")


async def _run_tov_analysis(
    doc_paths: List[str],
    smeta_path: Optional[str],
    project_name: str,
    project_duration_days: Optional[int],
    use_claude: bool,
    claude_mode: str,
    language: str
) -> Dict[str, Any]:
    """Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð°Ð½Ð°Ð»Ð¸Ð· TOV Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ TOVAgent"""
    try:
        # Import TOV agent
        from agents.tov_agent import get_tov_agent
        
        tov_agent = get_tov_agent()
        
        # Parse estimate data first
        estimate_data = {}
        if smeta_path:
            estimate_data = await _parse_estimate_file(smeta_path)
            logger.info(f"ðŸ“Š Ð Ð°ÑÐ¿Ð°Ñ€ÑÐµÐ½Ð° ÑÐ¼ÐµÑ‚Ð°: {len(estimate_data.get('work_items', []))} Ñ€Ð°Ð±Ð¾Ñ‚")
        
        # If no estimate, try to extract from documents
        if not estimate_data and doc_paths:
            estimate_data = await _extract_estimate_from_docs(doc_paths, use_claude, language)
            logger.info(f"ðŸ“„ Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²: {len(estimate_data.get('work_items', []))} Ñ€Ð°Ð±Ð¾Ñ‚")
        
        if not estimate_data.get('work_items'):
            # Create minimal estimate data for testing
            estimate_data = _create_minimal_estimate_data()
            logger.info("âš ï¸ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ TOV")
        
        # Prepare project constraints
        project_constraints = {
            "project_name": project_name,
            "duration_days": project_duration_days,
            "language": language,
            "use_ai": use_claude,
            "ai_mode": claude_mode
        }
        
        # Create TOV plan
        work_package = await tov_agent.create_tov_plan(estimate_data, project_constraints)
        
        # Prepare response data
        result = {
            "summary": {
                "project_name": project_name,
                "total_work_zones": len(work_package.work_zones),
                "total_duration_days": work_package.total_duration_days,
                "total_cost": work_package.total_cost,
                "critical_path_activities": len(work_package.critical_path)
            },
            "work_zones": [
                {
                    "zone_id": zone.zone_id,
                    "name": zone.name,
                    "activities": zone.activities,
                    "start_date": zone.start_date.isoformat(),
                    "end_date": zone.end_date.isoformat(),
                    "duration_days": zone.estimated_duration_days,
                    "floor_level": zone.floor_level,
                    "status": zone.status,
                    "resource_count": len(zone.resources),
                    "dependencies": zone.dependencies
                }
                for zone in work_package.work_zones
            ],
            "resource_requirements": [
                {
                    "type": req.resource_type,
                    "name": req.resource_name,
                    "quantity": req.quantity,
                    "unit": req.unit,
                    "cost_per_unit": req.cost_per_unit,
                    "total_cost": req.total_cost,
                    "priority": req.priority
                }
                for req in work_package.resource_requirements
            ],
            "critical_path": work_package.critical_path,
            "gantt_data": _generate_gantt_data(work_package.work_zones),
            "resource_utilization": _calculate_resource_utilization(work_package),
            "csv_export": tov_agent.export_to_csv(work_package),
            "json_export": tov_agent.export_to_json(work_package),
            "status": "completed"
        }
        
        logger.info("âœ… TOV Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ TOV Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
        return {
            "error": str(e),
            "status": "failed",
            "message": "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· TOV"
        }


async def _parse_estimate_file(smeta_path: str) -> Dict[str, Any]:
    """ÐŸÐ°Ñ€ÑÐ¸Ñ‚ Ñ„Ð°Ð¹Ð» ÑÐ¼ÐµÑ‚Ñ‹"""
    try:
        # Import parsers based on file extension
        file_ext = os.path.splitext(smeta_path.lower())[1]
        
        if file_ext in [".xlsx", ".xls"]:
            from parsers.smeta_parser import SmetaParser
            parser = SmetaParser()
            return parser.parse(smeta_path)
        elif file_ext == ".xml":
            from parsers.xml_smeta_parser import XMLSmetaParser
            parser = XMLSmetaParser()
            return parser.parse(smeta_path)
        elif file_ext == ".csv":
            import pandas as pd
            df = pd.read_csv(smeta_path)
            return _convert_dataframe_to_estimate(df)
        else:
            logger.warning(f"âš ï¸ ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐ¼ÐµÑ‚Ñ‹: {file_ext}")
            return {}
            
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° ÑÐ¼ÐµÑ‚Ñ‹: {e}")
        return {}


async def _extract_estimate_from_docs(doc_paths: List[str], use_claude: bool, language: str) -> Dict[str, Any]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÑÐ¼ÐµÑ‚Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"""
    try:
        # Use integration orchestrator to extract data
        from agents.integration_orchestrator import get_integration_orchestrator, IntegratedAnalysisRequest
        
        orchestrator = get_integration_orchestrator()
        
        request = IntegratedAnalysisRequest(
            doc_paths=doc_paths,
            smeta_path=None,
            material_query=None,
            use_claude=use_claude,
            claude_mode="enhancement",
            language=language
        )
        
        analysis_result = await orchestrator.run_integrated_analysis(request)
        
        # Extract estimate-relevant data
        return {
            "work_items": analysis_result.get("concrete_analysis", {}).get("matches", []),
            "materials": analysis_result.get("materials_analysis", {}).get("materials", []),
            "total_cost": 0,
            "total_volume": 0
        }
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²: {e}")
        return {}


def _create_minimal_estimate_data() -> Dict[str, Any]:
    """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸"""
    return {
        "work_items": [
            {
                "name": "Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°",
                "quantity": 100,
                "unit": "Ð¼3",
                "cost": 50000,
                "labor_hours": 80,
                "equipment": [{"name": "Ð­ÐºÑÐºÐ°Ð²Ð°Ñ‚Ð¾Ñ€", "quantity": 1, "cost_per_unit": 2000}]
            },
            {
                "name": "Ð’Ð¾Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ ÑÑ‚ÐµÐ½",
                "quantity": 200,
                "unit": "Ð¼2",
                "cost": 80000,
                "labor_hours": 120,
                "equipment": [{"name": "ÐšÑ€Ð°Ð½", "quantity": 1, "cost_per_unit": 3000}]
            },
            {
                "name": "Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ ÐºÑ€Ð¾Ð²Ð»Ð¸",
                "quantity": 150,
                "unit": "Ð¼2",
                "cost": 45000,
                "labor_hours": 60,
                "equipment": [{"name": "ÐŸÐ¾Ð´ÑŠÐµÐ¼Ð½Ð¸Ðº", "quantity": 1, "cost_per_unit": 1500}]
            }
        ],
        "materials": [
            {"name": "Ð‘ÐµÑ‚Ð¾Ð½ B25", "quantity": 100, "unit": "Ð¼3", "price": 3000, "total_cost": 300000},
            {"name": "ÐÑ€Ð¼Ð°Ñ‚ÑƒÑ€Ð° A500", "quantity": 5, "unit": "Ñ‚", "price": 45000, "total_cost": 225000},
            {"name": "ÐšÐ¸Ñ€Ð¿Ð¸Ñ‡ ÐºÐµÑ€Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹", "quantity": 10000, "unit": "ÑˆÑ‚", "price": 15, "total_cost": 150000}
        ],
        "total_cost": 675000,
        "total_volume": 100
    }


def _convert_dataframe_to_estimate(df) -> Dict[str, Any]:
    """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ DataFrame Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐ¼ÐµÑ‚Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    try:
        work_items = []
        materials = []
        
        for _, row in df.iterrows():
            # Try to identify if it's a work item or material
            name = str(row.get("name", row.get("ÐÐ°Ð¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ", "Unknown")))
            quantity = float(row.get("quantity", row.get("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾", 0)))
            unit = str(row.get("unit", row.get("Ð•Ð´Ð¸Ð½Ð¸Ñ†Ð°", "ÑˆÑ‚")))
            cost = float(row.get("cost", row.get("Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ", 0)))
            
            if "Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»" in name.lower() or "material" in name.lower():
                materials.append({
                    "name": name,
                    "quantity": quantity,
                    "unit": unit,
                    "price": cost / quantity if quantity > 0 else 0,
                    "total_cost": cost
                })
            else:
                work_items.append({
                    "name": name,
                    "quantity": quantity,
                    "unit": unit,
                    "cost": cost,
                    "labor_hours": quantity * 0.5,  # Estimate
                    "equipment": []
                })
        
        return {
            "work_items": work_items,
            "materials": materials,
            "total_cost": sum([item["cost"] for item in work_items]) + sum([mat["total_cost"] for mat in materials]),
            "total_volume": sum([item["quantity"] for item in work_items])
        }
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸ DataFrame: {e}")
        return {}


def _generate_gantt_data(work_zones) -> List[Dict[str, Any]]:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ Ð“Ð°Ð½Ñ‚Ð°"""
    gantt_data = []
    
    for zone in work_zones:
        gantt_data.append({
            "id": zone.zone_id,
            "name": zone.name,
            "start": zone.start_date.isoformat(),
            "end": zone.end_date.isoformat(),
            "duration": zone.estimated_duration_days,
            "progress": 0,  # 0% Ð´Ð»Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ñ… Ñ€Ð°Ð±Ð¾Ñ‚
            "dependencies": zone.dependencies,
            "type": "task",
            "floor_level": zone.floor_level
        })
    
    return gantt_data


def _calculate_resource_utilization(work_package) -> Dict[str, Any]:
    """Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²"""
    try:
        resource_summary = {
            "labor": {"total_hours": 0, "peak_demand": 0, "utilization": "medium"},
            "equipment": {"total_units": 0, "unique_types": 0, "utilization": "medium"},
            "materials": {"total_cost": 0, "critical_materials": 0, "availability": "good"}
        }
        
        # Analyze resource requirements
        for req in work_package.resource_requirements:
            if req.resource_type == "labor":
                resource_summary["labor"]["total_hours"] += req.quantity
            elif req.resource_type == "equipment":
                resource_summary["equipment"]["total_units"] += req.quantity
            elif req.resource_type == "material":
                resource_summary["materials"]["total_cost"] += req.total_cost
                if req.priority in ["high", "critical"]:
                    resource_summary["materials"]["critical_materials"] += 1
        
        # Calculate utilization metrics
        if resource_summary["labor"]["total_hours"] > 1000:
            resource_summary["labor"]["utilization"] = "high"
        elif resource_summary["labor"]["total_hours"] < 200:
            resource_summary["labor"]["utilization"] = "low"
        
        return resource_summary
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²: {e}")
        return {}