# app/routers/tzd_router.py - –í–ê–® TZD ROUTER –ü–û –ù–û–í–û–ô –°–ò–°–¢–ï–ú–ï
"""
TZD Router –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
–°–∏—Å—Ç–µ–º–∞ –Ω–∞–π–¥–µ—Ç —ç—Ç–æ—Ç —Ä–æ—É—Ç–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import List, Dict, Any, Optional
import tempfile
import os
import json
import logging
from pathlib import Path
from datetime import datetime

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
try:
    from agents.concrete_agent import ConcreteAgent
    CONCRETE_AGENT_AVAILABLE = True
except ImportError:
    CONCRETE_AGENT_AVAILABLE = False

try:
    from agents.tzd_reader.agent import tzd_reader
    TZD_AVAILABLE = True
except ImportError:
    TZD_AVAILABLE = False

from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)

# –í–ê–ñ–ù–û: –†–æ—É—Ç–µ—Ä –¥–æ–ª–∂–µ–Ω –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è –∏–º–µ–Ω–Ω–æ 'router' –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
router = APIRouter(
    prefix="/api/v1/tzd",
    tags=["TZD Reader"],
    responses={404: {"description": "Not found"}}
)

# Pydantic –º–æ–¥–µ–ª–∏
class TZDAnalysisResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ TZD"""
    success: bool
    analysis_id: str
    timestamp: str
    project_name: str
    project_scope: str
    materials: List[str]
    concrete_requirements: List[str]
    norms: List[str]
    functional_requirements: List[str]
    risks_and_constraints: List[str]
    estimated_complexity: str
    key_technologies: List[str]
    processing_metadata: Dict[str, Any]
    project_summary: Dict[str, Any] = Field(default_factory=dict)
    error_message: Optional[str] = None

# –ö–µ—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
analysis_cache = {}
analysis_counter = 0

@router.post("/analyze", response_model=TZDAnalysisResponse)
async def analyze_documents(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(..., description="–§–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (PDF, DOCX, TXT)"),
    ai_engine: str = Form(default="gpt", description="AI –¥–≤–∏–∂–æ–∫: gpt –∏–ª–∏ claude"),
    analysis_depth: str = Form(default="standard", description="–ì–ª—É–±–∏–Ω–∞: basic, standard, detailed"),
    focus_areas: str = Form(default="", description="–û–±–ª–∞—Å—Ç–∏ —Ñ–æ–∫—É—Å–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é"),
    project_context: Optional[str] = Form(None, description="–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞")
):
    """
    üéØ **–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é TZD Reader**
    
    **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω —Å–∏—Å—Ç–µ–º–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–æ—É—Ç–µ—Ä–æ–≤!**
    
    **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
    - üìÑ –ê–Ω–∞–ª–∏–∑ PDF, DOCX, TXT —Ñ–∞–π–ª–æ–≤
    - üèóÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —á–µ—à—Å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ ƒåSN EN 206+A2
    - ü§ñ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AI –∞–≥–µ–Ω—Ç–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
    - üìä –†–∞–∑–ª–∏—á–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
    
    **–û–±–ª–∞—Å—Ç–∏ —Ñ–æ–∫—É—Å–∞:**
    - `concrete`: –∞–Ω–∞–ª–∏–∑ –±–µ—Ç–æ–Ω–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
    - `materials`: —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
    - `norms`: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
    - `costs`: –∞–Ω–∞–ª–∏–∑ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    - `safety`: —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    
    **–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
    ```bash
    curl -X POST "/api/v1/tzd/analyze" \\
         -F "files=@document.pdf" \\
         -F "ai_engine=gpt" \\
         -F "analysis_depth=detailed" \\
         -F "focus_areas=concrete,norms"
    ```
    """
    
    # –î–µ–º–æ —Ä–µ–∂–∏–º –µ—Å–ª–∏ TZD –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    if not TZD_AVAILABLE:
        return TZDAnalysisResponse(
            success=False,
            analysis_id="demo_mode",
            timestamp=datetime.now().isoformat(),
            project_name="Demo Mode - TZD Reader",
            project_scope="TZD Reader –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
            materials=[],
            concrete_requirements=[],
            norms=["ƒåSN EN 206+A2", "ƒåSN EN 10025", "ƒåSN 73 0540"],
            functional_requirements=["–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥—É–ª—å tzd_reader"],
            risks_and_constraints=["–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –¥–µ–º–æ —Ä–µ–∂–∏–º–µ"],
            estimated_complexity="demo",
            key_technologies=["FastAPI", "Auto Router Discovery"],
            processing_metadata={"demo_mode": True},
            project_summary={},
            error_message="TZD Reader –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥—É–ª—å agents/tzd_reader/agent.py"
        )
    
    global analysis_counter
    analysis_counter += 1
    analysis_id = f"tzd_{analysis_counter}_{datetime.now().strftime('%H%M%S')}"
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    temp_dir = tempfile.mkdtemp(prefix="tzd_")
    file_paths = []
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for file in files:
            if file.filename:
                path = os.path.join(temp_dir, file.filename)
                content = await file.read()
                with open(path, "wb") as f:
                    f.write(content)
                file_paths.append(path)
        
        if not file_paths:
            raise HTTPException(status_code=400, detail="–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü–∞—Ä—Å–∏–º –æ–±–ª–∞—Å—Ç–∏ —Ñ–æ–∫—É—Å–∞
        focus_list = [area.strip() for area in focus_areas.split(",") if area.strip()] if focus_areas else []
        
        # –ê–Ω–∞–ª–∏–∑ —Å TZD Reader
        result = tzd_reader(
            files=file_paths,
            engine=ai_engine,
            base_dir=temp_dir
        )
        
        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Concrete Agent –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if CONCRETE_AGENT_AVAILABLE and "concrete" in focus_list:
            try:
                concrete_agent = ConcreteAgent()
                concrete_analysis = concrete_agent.analyze_concrete_requirements(
                    result.get('concrete_requirements', [])
                )
                result['concrete_analysis'] = concrete_analysis
                logger.info("‚úÖ Concrete Agent –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Concrete Agent error: {e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result['analysis_id'] = analysis_id
        result['timestamp'] = datetime.now().isoformat()
        result['auto_discovered'] = True  # –ú–∞—Ä–∫–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
        analysis_cache[analysis_id] = result
        
        # –§–æ–Ω–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        background_tasks.add_task(cleanup_temp_files, temp_dir)
        
        return TZDAnalysisResponse(
            success=True,
            analysis_id=analysis_id,
            timestamp=result['timestamp'],
            project_name=result.get('project_name', ''),
            project_scope=result.get('project_scope', ''),
            materials=result.get('materials', []),
            concrete_requirements=result.get('concrete_requirements', []),
            norms=result.get('norms', []),
            functional_requirements=result.get('functional_requirements', []),
            risks_and_constraints=result.get('risks_and_constraints', []),
            estimated_complexity=result.get('estimated_complexity', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞'),
            key_technologies=result.get('key_technologies', []),
            processing_metadata=result.get('processing_metadata', {}),
            project_summary=result.get('project_summary', {})
        )
        
    except Exception as e:
        cleanup_temp_files(temp_dir)
        logger.error(f"TZD analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/health")
async def tzd_health():
    """üè• –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è TZD —Å–∏—Å—Ç–µ–º—ã"""
    return {
        "service": "TZD Reader",
        "status": "healthy" if TZD_AVAILABLE else "limited",
        "auto_discovered": True,
        "tzd_reader": TZD_AVAILABLE,
        "concrete_integration": CONCRETE_AGENT_AVAILABLE,
        "cached_analyses": len(analysis_cache),
        "timestamp": datetime.now().isoformat(),
        "supported_formats": ["PDF", "DOCX", "TXT"],
        "ai_engines": ["gpt", "claude"],
        "czech_standards": ["ƒåSN EN 206+A2", "ƒåSN EN 10025", "ƒåSN 73 0540"]
    }

@router.get("/analysis/{analysis_id}")
async def get_analysis(analysis_id: str):
    """üìã –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ ID"""
    if analysis_id not in analysis_cache:
        raise HTTPException(status_code=404, detail="–ê–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return JSONResponse(content=analysis_cache[analysis_id])

@router.get("/capabilities")
async def get_capabilities():
    """üîç –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ TZD —Å–∏—Å—Ç–µ–º—ã"""
    
    # Check MinerU availability
    mineru_enabled = os.getenv("MINERU_ENABLED", "false").lower() == "true"
    try:
        import mineru
        mineru_available = True
    except ImportError:
        mineru_available = False
    
    return {
        "document_analysis": {
            "formats": ["PDF", "DOCX", "TXT"],
            "max_file_size": "10MB",
            "max_files": 10,
            "languages": ["Czech", "English"],
            "mineru_integration": {
                "available": mineru_available,
                "enabled": mineru_enabled,
                "description": "Enhanced PDF text/structure extraction"
            }
        },
        "ai_analysis": {
            "engines": ["gpt-4", "claude-3.5"],
            "depths": ["basic", "standard", "detailed", "expert"],
            "focus_areas": ["concrete", "materials", "norms", "costs", "safety"]
        },
        "response_fields": {
            "standard_fields": [
                "project_name", "project_scope", "materials",
                "concrete_requirements", "norms", "functional_requirements",
                "risks_and_constraints", "estimated_complexity", "key_technologies"
            ],
            "enhanced_fields": {
                "project_summary": {
                    "description": "Structured project summary by sections",
                    "sections": ["overview", "scope", "concrete", "materials", "norms", "risks", "schedule", "costs", "deliverables"]
                },
                "processing_metadata": {
                    "description": "Processing statistics and configuration",
                    "includes": ["processed_files", "processing_time", "ai_engine", "mineru_used"]
                }
            }
        },
        "czech_standards": {
            "concrete": "ƒåSN EN 206+A2",
            "steel": "ƒåSN EN 10025", 
            "thermal": "ƒåSN 73 0540",
            "fire_safety": "ƒåSN 73 0802"
        },
        "integrations": {
            "concrete_agent": CONCRETE_AGENT_AVAILABLE,
            "auto_discovery": True,
            "export_formats": ["JSON", "Excel"]
        },
        "auto_registration": {
            "discovered_by": "RouterRegistry",
            "registration_time": "startup",
            "module_path": "app.routers.tzd_router"
        }
    }

async def cleanup_temp_files(temp_dir: str):
    """üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        import shutil
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {temp_dir}")
    except Exception as e:
        logger.error(f"‚ùå Cleanup error: {e}")
