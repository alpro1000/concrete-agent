# app/routers/tzd_router.py - TZD READER SYSTEM
"""
TZD Router –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞–Ω–∏–π
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π LLM —á–µ—Ä–µ–∑ Orchestrator
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import List, Dict, Any, Optional
import tempfile
import os
import json
import logging
from pathlib import Path
from datetime import datetime

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–∞–º–∏
try:
    from agents.tzd_reader.agent import tzd_reader
    from agents.tzd_reader.security import FileSecurityValidator, SecurityError
    TZD_AVAILABLE = True
except ImportError:
    TZD_AVAILABLE = False
    logger.warning("TZD Reader not available")

from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)

# –í–ê–ñ–ù–û: –†–æ—É—Ç–µ—Ä –¥–æ–ª–∂–µ–Ω –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è –∏–º–µ–Ω–Ω–æ 'router' –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
router = APIRouter(
    prefix="/api/v1/tzd",
    tags=["TZD Reader"],
    responses={404: {"description": "Not found"}}
)

# Pydantic –º–æ–¥–µ–ª–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ–≤–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
class TZDAnalysisResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ TZD –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    success: bool
    analysis_id: str
    timestamp: str
    project_object: str
    requirements: List[str]
    norms: List[str]
    constraints: List[str] 
    environment: str
    functions: List[str]
    processing_metadata: Dict[str, Any]
    error_message: Optional[str] = None

# –ö–µ—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
analysis_cache = {}
analysis_counter = 0

@router.post("/analyze", response_model=TZDAnalysisResponse)
async def analyze_tzd_documents(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(..., description="–§–∞–π–ª—ã –¢–ó –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (PDF, DOCX, TXT)"),
    ai_engine: str = Form(default="auto", description="AI –¥–≤–∏–∂–æ–∫: gpt, claude, auto"),
    project_context: Optional[str] = Form(None, description="–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞")
):
    """
    üéØ **–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é TZD Reader**
    
    **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:**
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: 10MB
    - –î–æ–ø—É—Å—Ç–∏–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .pdf, .docx, .txt
    - –ó–∞—â–∏—Ç–∞ –æ—Ç path traversal
    
    **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
    - üìÑ –ê–Ω–∞–ª–∏–∑ PDF, DOCX, TXT —Ñ–∞–π–ª–æ–≤
    - üèóÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –¢–ó
    - ü§ñ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LLM —á–µ—Ä–µ–∑ Orchestrator (Claude, GPT, Perplexity)
    - üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON –æ—Ç–≤–µ—Ç
    
    **–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
    ```bash
    curl -X POST "/api/v1/tzd/analyze" \\
         -F "files=@document.pdf" \\
         -F "ai_engine=auto"
    ```
    """
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ TZD –º–æ–¥—É–ª—è
    if not TZD_AVAILABLE:
        return TZDAnalysisResponse(
            success=False,
            analysis_id="error_no_tzd",
            timestamp=datetime.now().isoformat(),
            project_object="–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏",
            requirements=["–ú–æ–¥—É–ª—å TZD Reader –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"],
            norms=[],
            constraints=["–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ"],
            environment="–î–µ–º–æ —Ä–µ–∂–∏–º",
            functions=[],
            processing_metadata={"demo_mode": True},
            error_message="TZD Reader –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥—É–ª—è agents/tzd_reader/"
        )
    
    global analysis_counter
    analysis_counter += 1
    analysis_id = f"tzd_{analysis_counter}_{datetime.now().strftime('%H%M%S')}"
    
    # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    temp_dir = tempfile.mkdtemp(prefix="tzd_secure_")
    file_paths = []
    
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        validator = FileSecurityValidator()
        
        for file in files:
            if not file.filename:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            try:
                validator.validate_file_extension(file.filename)
            except SecurityError as e:
                raise HTTPException(status_code=400, detail=f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {str(e)}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–∞–∑–º–µ—Ä–∞
            safe_filename = Path(file.filename).name  # –ó–∞—â–∏—Ç–∞ –æ—Ç path traversal
            file_path = os.path.join(temp_dir, safe_filename)
            
            content = await file.read()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
            if len(content) > 10 * 1024 * 1024:  # 10MB
                raise HTTPException(status_code=400, detail=f"–§–∞–π–ª {safe_filename} –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç 10MB")
            
            with open(file_path, "wb") as f:
                f.write(content)
            file_paths.append(file_path)
        
        if not file_paths:
            raise HTTPException(status_code=400, detail="–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ê–Ω–∞–ª–∏–∑ —Å TZD Reader —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
        logger.info(f"Starting TZD analysis with {len(file_paths)} files using engine: {ai_engine}")
        
        result = tzd_reader(
            files=file_paths,
            engine=ai_engine,
            base_dir=temp_dir
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        result['analysis_id'] = analysis_id
        result['timestamp'] = datetime.now().isoformat()
        result['llm_orchestrator_used'] = True
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        analysis_cache[analysis_id] = result
        
        # –§–æ–Ω–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        background_tasks.add_task(cleanup_temp_files, temp_dir)
        
        return TZDAnalysisResponse(
            success=True,
            analysis_id=analysis_id,
            timestamp=result['timestamp'],
            project_object=result.get('project_object', ''),
            requirements=result.get('requirements', []),
            norms=result.get('norms', []),
            constraints=result.get('constraints', []),
            environment=result.get('environment', ''),
            functions=result.get('functions', []),
            processing_metadata=result.get('processing_metadata', {})
        )
        
    except SecurityError as e:
        cleanup_temp_files(temp_dir)
        logger.error(f"Security error in TZD analysis: {e}")
        raise HTTPException(status_code=400, detail=f"–ù–∞—Ä—É—à–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {str(e)}")
    except Exception as e:
        cleanup_temp_files(temp_dir)
        logger.error(f"TZD analysis error: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")

@router.get("/health")
async def tzd_health():
    """üè• –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è TZD —Å–∏—Å—Ç–µ–º—ã"""
    return {
        "service": "TZD Reader",
        "status": "healthy" if TZD_AVAILABLE else "limited",
        "tzd_reader_available": TZD_AVAILABLE,
        "cached_analyses": len(analysis_cache),
        "timestamp": datetime.now().isoformat(),
        "security": {
            "max_file_size": "10MB",
            "allowed_extensions": [".pdf", ".docx", ".txt"],
            "path_traversal_protection": True
        },
        "supported_formats": ["PDF", "DOCX", "TXT"],
        "ai_engines": ["gpt", "claude", "auto"],
        "orchestrator_integration": True
    }

@router.get("/analysis/{analysis_id}")
async def get_analysis_result(analysis_id: str):
    """üìã –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ ID"""
    if analysis_id not in analysis_cache:
        raise HTTPException(status_code=404, detail="–ê–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return JSONResponse(content=analysis_cache[analysis_id])

async def cleanup_temp_files(temp_dir: str):
    """üßπ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        import shutil
        if os.path.exists(temp_dir) and temp_dir.startswith('/tmp/'):
            shutil.rmtree(temp_dir)
            logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {temp_dir}")
    except Exception as e:
        logger.error(f"‚ùå Cleanup error: {e}")
