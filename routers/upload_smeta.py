# routers/upload_smeta.py
"""
Estimates/BOQ Upload Router
Handles XLSX, XML, CSV, XC4 and other estimate formats
"""
from fastapi import APIRouter, UploadFile, File, HTTPException, Form, Depends
from fastapi.responses import JSONResponse
from typing import List, Optional
import tempfile
import os
import shutil
import logging
from config.settings import settings

router = APIRouter()
logger = logging.getLogger(__name__)

# Supported file types for estimates
ALLOWED_SMETA_EXTENSIONS = [".xlsx", ".xls", ".xml", ".csv", ".xc4", ".json", ".ods"]

@router.post("/smeta")
async def upload_estimates(
    files: List[UploadFile] = File(..., description="Ð¡Ð¼ÐµÑ‚Ñ‹ Ð¸ Ð²ÐµÐ´Ð¾Ð¼Ð¾ÑÑ‚Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚ (XLSX, XML, CSV, XC4)"),
    project_name: str = Form("Untitled Project", description="ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"),
    estimate_type: str = Form("general", description="Ð¢Ð¸Ð¿ ÑÐ¼ÐµÑ‚Ñ‹: general, detailed, comparative"),
    auto_analyze: bool = Form(True, description="ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¼ÐµÑ‚Ñ‹"),
    language: str = Form("cz", description="Ð¯Ð·Ñ‹Ðº Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: cz, en, ru")
):
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¼ÐµÑ‚ Ð¸ Ð²ÐµÐ´Ð¾Ð¼Ð¾ÑÑ‚ÐµÐ¹ Ñ€Ð°Ð±Ð¾Ñ‚
    
    ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹:
    - XLSX/XLS: Excel ÑÐ¼ÐµÑ‚Ñ‹
    - XML: ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¼ÐµÑ‚Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    - CSV: Ñ‚Ð°Ð±Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    - XC4: Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ XChange
    - JSON: JSON ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ ÑÐ¼ÐµÑ‚
    - ODS: OpenDocument Spreadsheet
    """
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Validate file types
        uploaded_files = []
        for file in files:
            if not file.filename:
                continue
                
            file_ext = os.path.splitext(file.filename.lower())[1]
            if file_ext not in ALLOWED_SMETA_EXTENSIONS:
                raise HTTPException(
                    status_code=400,
                    detail=f"âŒ ÐÐµÐ´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ñ„Ð°Ð¹Ð»Ð°: {file.filename}. "
                          f"Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ñ‹: {', '.join(ALLOWED_SMETA_EXTENSIONS)}"
                )
            
            # Save file to temp directory
            file_path = os.path.join(temp_dir, file.filename)
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            uploaded_files.append({
                "filename": file.filename,
                "path": file_path,
                "size": len(content),
                "type": _detect_estimate_type(file.filename, content),
                "format": file_ext[1:]  # Remove the dot
            })
            
            logger.info(f"ðŸ“Š Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑÐ¼ÐµÑ‚Ð°: {file.filename}")
        
        if not uploaded_files:
            raise HTTPException(status_code=400, detail="âŒ ÐÐµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°")
        
        # Prepare analysis result
        result = {
            "upload_type": "estimates_boq",
            "project_name": project_name,
            "estimate_type": estimate_type,
            "total_files": len(uploaded_files),
            "files": uploaded_files,
            "supported_agents": ["VolumeAgent", "MaterialAgent", "ConcreteAgent", "TOVPlanner"],
            "status": "uploaded_successfully"
        }
        
        # Auto-analyze if requested
        if auto_analyze:
            try:
                analysis_result = await _analyze_estimates(
                    uploaded_files, estimate_type, language
                )
                result["analysis"] = analysis_result
                result["status"] = "analyzed_successfully"
            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
                result["analysis"] = {
                    "error": str(e),
                    "status": "analysis_failed"
                }
                result["status"] = "uploaded_but_analysis_failed"
        
        return JSONResponse(content=result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÑÐ¼ÐµÑ‚: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Ð’Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°: {str(e)}"
        )
    finally:
        # Cleanup temp files
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            logger.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹: {e}")


def _detect_estimate_type(filename: str, content: bytes) -> str:
    """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ñ‚Ð¸Ð¿ ÑÐ¼ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°"""
    filename_lower = filename.lower()
    
    # Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ ÑÐ¼ÐµÑ‚Ð°
    if any(keyword in filename_lower for keyword in ["local", "Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ", "Ð»Ð¾ÐºÐ°Ð»"]):
        return "local_estimate"
    
    # ÐžÐ±ÑŠÐµÐºÑ‚Ð½Ð°Ñ ÑÐ¼ÐµÑ‚Ð°
    if any(keyword in filename_lower for keyword in ["object", "Ð¾Ð±ÑŠÐµÐºÑ‚", "Ð¾Ð±Ñ‰Ð°Ñ"]):
        return "object_estimate"
    
    # Ð¡Ð²Ð¾Ð´Ð½Ð°Ñ ÑÐ¼ÐµÑ‚Ð°
    if any(keyword in filename_lower for keyword in ["summary", "ÑÐ²Ð¾Ð´Ð½Ð°Ñ", "total"]):
        return "summary_estimate"
    
    # Ð’ÐµÐ´Ð¾Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑŠÐµÐ¼Ð¾Ð² Ñ€Ð°Ð±Ð¾Ñ‚
    if any(keyword in filename_lower for keyword in ["volume", "Ð¾Ð±ÑŠÐµÐ¼", "Ñ€Ð°Ð±Ð¾Ñ‚", "work"]):
        return "work_volume_statement"
    
    # Ð ÐµÑÑƒÑ€ÑÐ½Ð°Ñ Ð²ÐµÐ´Ð¾Ð¼Ð¾ÑÑ‚ÑŒ
    if any(keyword in filename_lower for keyword in ["resource", "Ñ€ÐµÑÑƒÑ€Ñ", "material"]):
        return "resource_statement"
    
    # Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÐ¼ÐµÑ‚Ð°
    if any(keyword in filename_lower for keyword in ["compare", "ÑÑ€Ð°Ð²Ð½", "comparison"]):
        return "comparative_estimate"
    
    # ÐŸÐ¾ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÑŽ Ñ„Ð°Ð¹Ð»Ð°
    ext = os.path.splitext(filename_lower)[1]
    if ext in [".xlsx", ".xls"]:
        return "excel_estimate"
    elif ext == ".xml":
        return "xml_estimate"
    elif ext == ".csv":
        return "csv_estimate"
    elif ext == ".xc4":
        return "xchange_estimate"
    elif ext == ".json":
        return "json_estimate"
    
    return "general_estimate"


async def _analyze_estimates(files: List[dict], estimate_type: str, language: str) -> dict:
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ¼ÐµÑ‚Ñ‹ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²"""
    try:
        # Import agents
        from agents.integration_orchestrator import get_integration_orchestrator
        
        orchestrator = get_integration_orchestrator()
        
        # Use first file as main estimate (can be enhanced to process multiple)
        main_estimate_path = files[0]["path"] if files else None
        
        # Run integrated analysis focusing on volume and materials
        from agents.integration_orchestrator import IntegratedAnalysisRequest
        
        request = IntegratedAnalysisRequest(
            doc_paths=[],  # No docs for estimate-only analysis
            smeta_path=main_estimate_path,
            material_query=None,
            use_claude=True,
            claude_mode="enhancement",
            language=language
        )
        
        analysis_result = await orchestrator.run_integrated_analysis(request)
        
        # Parse estimate data
        estimate_data = await _parse_estimate_files(files)
        
        # Extract relevant parts for estimate analysis
        return {
            "summary": analysis_result.get("summary", {}),
            "volume_analysis": analysis_result.get("volume_analysis", {}),
            "materials_analysis": analysis_result.get("materials_analysis", {}),
            "concrete_analysis": analysis_result.get("concrete_analysis", {}),
            "estimate_data": estimate_data,
            "tov_planning": await _generate_tov_plan(estimate_data),
            "processing_status": analysis_result.get("status", {}),
            "analysis_timestamp": analysis_result.get("timestamp")
        }
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐ¼ÐµÑ‚: {e}")
        return {
            "error": str(e),
            "status": "failed",
            "message": "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ¼ÐµÑ‚"
        }


async def _parse_estimate_files(files: List[dict]) -> dict:
    """ÐŸÐ°Ñ€ÑÐ¸Ñ‚ ÑÐ¼ÐµÑ‚Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""
    try:
        # Import parsers
        from parsers.smeta_parser import SmetaParser
        from parsers.xml_smeta_parser import XMLSmetaParser
        
        parsed_data = {
            "total_cost": 0.0,
            "total_volume": 0.0,
            "work_items": [],
            "materials": [],
            "resources": []
        }
        
        for file_info in files:
            file_path = file_info["path"]
            file_format = file_info["format"]
            
            try:
                if file_format in ["xlsx", "xls", "csv"]:
                    parser = SmetaParser()
                    file_data = parser.parse(file_path)
                elif file_format == "xml":
                    parser = XMLSmetaParser()
                    file_data = parser.parse(file_path)
                else:
                    logger.warning(f"âš ï¸ ÐÐµÐ¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚: {file_format}")
                    continue
                
                # Merge parsed data
                if file_data:
                    parsed_data["total_cost"] += file_data.get("total_cost", 0)
                    parsed_data["total_volume"] += file_data.get("total_volume", 0)
                    parsed_data["work_items"].extend(file_data.get("work_items", []))
                    parsed_data["materials"].extend(file_data.get("materials", []))
                    parsed_data["resources"].extend(file_data.get("resources", []))
                    
            except Exception as e:
                logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ñ„Ð°Ð¹Ð»Ð° {file_info['filename']}: {e}")
                continue
        
        return parsed_data
        
    except Exception as e:
        logger.error(f"âŒ ÐžÐ±Ñ‰Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° ÑÐ¼ÐµÑ‚: {e}")
        return {"error": str(e)}


async def _generate_tov_plan(estimate_data: dict) -> dict:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð»Ð°Ð½ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð² (Ð¢Ñ€ÑƒÐ´-ÐžÐ±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ-ÐœÐ°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ñ‹) Ð¸ Ð·Ð°Ñ…Ð²Ð°Ñ‚ÐºÐ¸"""
    try:
        # This would integrate with TOVPlanner agent when implemented
        # For now, return placeholder data
        
        work_items = estimate_data.get("work_items", [])
        materials = estimate_data.get("materials", [])
        
        return {
            "work_packages": len(work_items),
            "total_labor_hours": sum(item.get("labor_hours", 0) for item in work_items),
            "equipment_requirements": _extract_equipment_needs(work_items),
            "material_requirements": _extract_material_needs(materials),
            "suggested_zones": _suggest_work_zones(work_items),
            "estimated_duration_days": _estimate_project_duration(work_items),
            "critical_path": _identify_critical_activities(work_items),
            "status": "preliminary_plan_generated"
        }
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ TOV Ð¿Ð»Ð°Ð½Ð°: {e}")
        return {"error": str(e), "status": "tov_planning_failed"}


def _extract_equipment_needs(work_items: List[dict]) -> List[dict]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸ÑŽ"""
    equipment = []
    for item in work_items:
        if "equipment" in item:
            equipment.extend(item["equipment"])
    return equipment


def _extract_material_needs(materials: List[dict]) -> List[dict]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð°Ð¼"""
    return materials


def _suggest_work_zones(work_items: List[dict]) -> List[dict]:
    """ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ Ñ€Ð°Ð·Ð±Ð¸Ð²ÐºÑƒ Ð½Ð° Ð·Ð°Ñ…Ð²Ð°Ñ‚ÐºÐ¸"""
    # Simplified zone suggestion based on work types
    zones = []
    current_zone = {"zone_id": 1, "activities": [], "estimated_duration": 0}
    
    for item in work_items:
        current_zone["activities"].append(item.get("name", "Unknown activity"))
        current_zone["estimated_duration"] += item.get("duration", 1)
        
        # Simple logic: create new zone every 10 activities
        if len(current_zone["activities"]) >= 10:
            zones.append(current_zone)
            current_zone = {
                "zone_id": len(zones) + 1, 
                "activities": [], 
                "estimated_duration": 0
            }
    
    if current_zone["activities"]:
        zones.append(current_zone)
    
    return zones


def _estimate_project_duration(work_items: List[dict]) -> int:
    """ÐžÑ†ÐµÐ½Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ð±Ñ‰ÑƒÑŽ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"""
    total_duration = sum(item.get("duration", 1) for item in work_items)
    # Assume some parallelization
    return max(1, int(total_duration * 0.7))


def _identify_critical_activities(work_items: List[dict]) -> List[str]:
    """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹"""
    # Simplified: identify items with longest duration or high cost
    critical = []
    for item in work_items:
        duration = item.get("duration", 0)
        cost = item.get("cost", 0)
        if duration > 5 or cost > 100000:  # Thresholds
            critical.append(item.get("name", "Unknown"))
    return critical