# routers/upload_docs.py
"""
Project Documents Upload Router
Handles technical specifications, geological materials, PDF/DOCX/TXT documents
"""
from fastapi import APIRouter, UploadFile, File, HTTPException, Form, Depends
from fastapi.responses import JSONResponse
from typing import List, Optional
import tempfile
import os
import shutil
import logging
from config.settings import settings

router = APIRouter()
logger = logging.getLogger(__name__)

# Supported file types for project documents
ALLOWED_DOCS_EXTENSIONS = [".pdf", ".docx", ".txt", ".doc", ".rtf"]

@router.post("/docs")
async def upload_project_documents(
    files: List[UploadFile] = File(..., description="–ü—Ä–æ–µ–∫—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (TZ, PDF, DOCX, TXT, –≥–µ–æ–ª–æ–≥–∏—è)"),
    project_name: str = Form("Untitled Project", description="–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"),
    auto_analyze: bool = Form(True, description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"),
    language: str = Form("cz", description="–Ø–∑—ã–∫ –∞–Ω–∞–ª–∏–∑–∞: cz, en, ru")
):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
    - PDF: —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è, –≥–µ–æ–ª–æ–≥–∏—è, —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
    - DOCX: —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
    - TXT: –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    - DOC: —Å—Ç–∞—Ä—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã Word
    - RTF: —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Validate file types
        uploaded_files = []
        for file in files:
            if not file.filename:
                continue
                
            file_ext = os.path.splitext(file.filename.lower())[1]
            if file_ext not in ALLOWED_DOCS_EXTENSIONS:
                raise HTTPException(
                    status_code=400,
                    detail=f"‚ùå –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file.filename}. "
                          f"–†–∞–∑—Ä–µ—à–µ–Ω—ã: {', '.join(ALLOWED_DOCS_EXTENSIONS)}"
                )
            
            # Save file to temp directory
            file_path = os.path.join(temp_dir, file.filename)
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            uploaded_files.append({
                "filename": file.filename,
                "path": file_path,
                "size": len(content),
                "type": _detect_document_type(file.filename, content)
            })
            
            logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–µ–∫—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {file.filename}")
        
        if not uploaded_files:
            raise HTTPException(status_code=400, detail="‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        
        # Prepare analysis result
        result = {
            "upload_type": "project_documents",
            "project_name": project_name,
            "total_files": len(uploaded_files),
            "files": uploaded_files,
            "supported_agents": ["TZDReader", "ConcreteAgent", "MaterialAgent"],
            "status": "uploaded_successfully"
        }
        
        # Auto-analyze if requested
        if auto_analyze:
            try:
                analysis_result = await _analyze_project_documents(
                    uploaded_files, language
                )
                result["analysis"] = analysis_result
                result["status"] = "analyzed_successfully"
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
                result["analysis"] = {
                    "error": str(e),
                    "status": "analysis_failed"
                }
                result["status"] = "uploaded_but_analysis_failed"
        
        return JSONResponse(content=result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"
        )
    finally:
        # Cleanup temp files
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {e}")


def _detect_document_type(filename: str, content: bytes) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    filename_lower = filename.lower()
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ
    if any(keyword in filename_lower for keyword in ["tz", "—Ç–µ—Ö–∑–∞–¥–∞–Ω–∏–µ", "tech", "specification"]):
        return "technical_specification"
    
    # –ì–µ–æ–ª–æ–≥–∏—è
    if any(keyword in filename_lower for keyword in ["geo", "–≥–µ–æ–ª–æ–≥–∏—è", "–≥—Ä—É–Ω—Ç", "soil"]):
        return "geological_report"
    
    # –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    if any(keyword in filename_lower for keyword in ["gost", "–≥–æ—Å—Ç", "—Å–Ω–∏–ø", "sp", "norm"]):
        return "regulatory_document"
    
    # –ü—Ä–æ–µ–∫—Ç–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    if any(keyword in filename_lower for keyword in ["project", "–ø—Ä–æ–µ–∫—Ç", "–ø–ª–∞–Ω", "plan"]):
        return "project_documentation"
    
    # –ü–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é —Ñ–∞–π–ª–∞
    ext = os.path.splitext(filename_lower)[1]
    if ext == ".pdf":
        return "pdf_document"
    elif ext in [".docx", ".doc"]:
        return "word_document"
    elif ext == ".txt":
        return "text_document"
    
    return "general_document"


async def _analyze_project_documents(files: List[dict], language: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é –∞–≥–µ–Ω—Ç–æ–≤"""
    try:
        # Import agents
        from agents.integration_orchestrator import get_integration_orchestrator
        from agents.tzd_reader import TZDReader
        
        orchestrator = get_integration_orchestrator()
        
        # Prepare file paths for analysis
        doc_paths = [f["path"] for f in files]
        
        # Run integrated analysis
        from agents.integration_orchestrator import IntegratedAnalysisRequest
        
        request = IntegratedAnalysisRequest(
            doc_paths=doc_paths,
            smeta_path=None,  # No estimate file for docs-only analysis
            material_query=None,
            use_claude=True,
            claude_mode="enhancement",
            language=language
        )
        
        analysis_result = await orchestrator.run_integrated_analysis(request)
        
        # Extract relevant parts for document analysis
        return {
            "summary": analysis_result.get("summary", {}),
            "technical_specification": analysis_result.get("tzd_analysis", {}),
            "concrete_analysis": analysis_result.get("concrete_analysis", {}),
            "materials_found": analysis_result.get("materials_analysis", {}).get("materials", []),
            "processing_status": analysis_result.get("status", {}),
            "analysis_timestamp": analysis_result.get("timestamp")
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        return {
            "error": str(e),
            "status": "failed",
            "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        }