"""
üß± –ü–æ–ª–Ω—ã–π ConcreteAgentHybrid - –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —Ç–æ—á–Ω—ã–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º
–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã:
1. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Å–µ–≥–æ, —á—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ "C"
2. –ü–ª–æ—Ö–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—à—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
"""

import re
import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
try:
    from parsers.doc_parser import DocParser
    from parsers.smeta_parser import SmetaParser
    from utils.claude_client import get_claude_client
    from config.settings import settings
    from outputs.save_report import save_merged_report
except ImportError:
    print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Ä–∞–±–æ—Ç–∞–µ–º –≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–º —Ä–µ–∂–∏–º–µ")
    DocParser = None
    SmetaParser = None

logger = logging.getLogger(__name__)

@dataclass
class ConcreteMatch:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–∞—Ä–∫–∏ –±–µ—Ç–æ–Ω–∞"""
    grade: str
    context: str
    location: str
    confidence: float
    method: str
    coordinates: Optional[Tuple[int, int, int, int]] = None
    structural_element: Optional[str] = None
    exposure_class: Optional[str] = None
    position: Optional[Dict[str, int]] = None

@dataclass
class StructuralElement:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞"""
    name: str
    concrete_grade: Optional[str]
    location: str
    context: str
    exposure_requirements: List[str]
    min_strength_required: Optional[str] = None

@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞"""
    success: bool
    total_matches: int
    analysis_method: str
    processing_time: float
    concrete_summary: List[Dict[str, Any]]
    structural_elements: List[Dict[str, Any]]
    compliance_issues: List[str]
    recommendations: List[str]
    confidence_score: float

class CzechLanguageProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —á–µ—à—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏"""
    
    def __init__(self):
        self.concrete_terms = {
            # –ë–µ—Ç–æ–Ω –≤–æ –≤—Å–µ—Ö —Å–∫–ª–æ–Ω–µ–Ω–∏—è—Ö
            'beton': [
                'beton', 'betonu', 'betony', 'beton≈Ø', 'betonem', 'betonech',
                'betonov√°', 'betonov√©', 'betonov√Ω', 'betonovou', 'betonov√Ωch',
                'betonov√Ωm', 'betonami', 'beton√°≈ôsk√Ω', 'beton√°≈ôsk√©'
            ],
            # –ö–ª–∞—Å—Å/—Å—Ç–µ–ø–µ–Ω—å
            't≈ô√≠da': [
                't≈ô√≠da', 't≈ô√≠dy', 't≈ô√≠dƒõ', 't≈ô√≠du', 't≈ô√≠dou', 't≈ô√≠d√°ch', 
                't≈ô√≠dami', 't≈ô√≠d', 't≈ô√≠d√°m', 't≈ô√≠dou'
            ],
            # –°—Ç–µ–ø–µ–Ω—å
            'stupe≈à': [
                'stupe≈à', 'stupnƒõ', 'stupni', 'stupnƒõm', 'stupn√≠ch', 
                'stup≈à≈Ø', 'stup≈à≈Øm', 'stupni'
            ],
            # –ü—Ä–æ—á–Ω–æ—Å—Ç—å
            'pevnost': [
                'pevnost', 'pevnosti', 'pevnost√≠', 'pevnostem', 'pevnostech',
                'pevnostn√≠', 'pevnostn√≠m', 'pevnostn√≠ch'
            ],
            # –ö–∞—á–µ—Å—Ç–≤–æ
            'kvalita': [
                'kvalita', 'kvality', 'kvalitƒõ', 'kvalitou', 'kvalit', 
                'kvalit√°ch', 'kvalitn√≠', 'kvalitn√≠m'
            ],
            # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
            'konstrukce': [
                'konstrukce', 'konstrukc√≠', 'konstrukc√≠m', 'konstrukcemi', 
                'konstrukc√≠ch', 'konstrukƒçn√≠', 'konstrukƒçn√≠m'
            ],
            # –¶–µ–º–µ–Ω—Ç
            'cement': [
                'cement', 'cementu', 'cementy', 'cement≈Ø', 'cementem', 
                'cementech', 'cementov√Ω', 'cementov√©'
            ],
            # –ó–∞–ª–∏–≤–∫–∞
            'beton√°≈æ': [
                'beton√°≈æ', 'beton√°≈æe', 'beton√°≈æi', 'beton√°≈æ√≠', 
                'betonov√°n√≠', 'betonovat'
            ],
            # –°–º–µ—Å—å
            'smƒõs': [
                'smƒõs', 'smƒõsi', 'smƒõs√≠', 'smƒõsem', 'smƒõs√≠ch', 
                'smƒõsov√Ω', 'smƒõsov√©'
            ],
            # –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ
            'v√Ωroba': [
                'v√Ωroba', 'v√Ωroby', 'v√Ωrobƒõ', 'v√Ωrobu', 'v√Ωrobou',
                'v√Ωrobn√≠', 'v√Ωrobn√≠k', 'vyr√°bƒõt'
            ]
        }
        
        self.structural_elements = {
            'z√°klad': ['z√°klad', 'z√°klady', 'z√°klad≈Ø', 'z√°kladem', 'z√°kladn√≠', 'z√°kladov√°'],
            'pil√≠≈ô': ['pil√≠≈ô', 'pil√≠≈ôe', 'pil√≠≈ô≈Ø', 'pil√≠≈ôem', 'pil√≠≈ôi'],
            'sloup': ['sloup', 'sloupy', 'sloup≈Ø', 'sloupem', 'sloupu'],
            'stƒõna': ['stƒõna', 'stƒõny', 'stƒõn', 'stƒõnou', 'stƒõnƒõ'],
            'deska': ['deska', 'desky', 'desek', 'deskou', 'desce'],
            'nosn√≠k': ['nosn√≠k', 'nosn√≠ky', 'nosn√≠k≈Ø', 'nosn√≠kem', 'nosn√≠ku'],
            'vƒõnec': ['vƒõnec', 'vƒõnce', 'vƒõnc≈Ø', 'vƒõncem', 'vƒõnci'],
            'schodi≈°tƒõ': ['schodi≈°tƒõ', 'schodi≈°≈•', 'schodi≈°tƒõm', 'schodi≈°ti'],
            'mostovka': ['mostovka', 'mostovky', 'mostovkou', 'mostovce'],
            'vozovka': ['vozovka', 'vozovky', 'vozovkou', 'vozovce'],
            'gar√°≈æ': ['gar√°≈æ', 'gar√°≈æe', 'gar√°≈æ√≠', 'gar√°≈æou', 'gar√°≈æ√≠ch'],
            '≈ô√≠ms': ['≈ô√≠ms', '≈ô√≠msa', '≈ô√≠msy', '≈ô√≠msou', '≈ô√≠ms√°ch']
        }

        self.exclusion_terms = {
            # –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ
            'admin': ['str√°nka', 'strana', 'str.', 'page', 'kapitola', 'odd√≠l', 'ƒç√°st', 'section'],
            # –ö–æ–¥—ã –∏ –Ω–æ–º–µ—Ä–∞  
            'codes': ['k√≥d', 'ƒç√≠slo', 'number', 'id', 'identifik√°tor', 'oznaƒçen√≠'],
            # –ö–æ–º–ø–∞–Ω–∏–∏
            'companies': ['firma', 'spoleƒçnost', 'company', 'spol.', 's.r.o.', 'a.s.'],
            # –î–∞—Ç—ã –∏ –≤—Ä–µ–º—è
            'dates': ['datum', 'date', 'rok', 'year', 'mƒõs√≠c', 'month', 'den', 'day'],
            # –¶–µ–Ω—ã –∏ –¥–µ–Ω—å–≥–∏
            'money': ['cena', 'price', 'cost', 'kƒç', 'koruna', 'euro', 'eur'],
            # –ö–æ–Ω—Ç–∞–∫—Ç—ã
            'contacts': ['telefon', 'tel', 'phone', 'email', 'adresa', 'address']
        }

    def count_concrete_terms(self, text: str) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –±–µ—Ç–æ–Ω–∞"""
        text_lower = text.lower()
        count = 0
        
        for category, terms in self.concrete_terms.items():
            found = any(term in text_lower for term in terms)
            if found:
                count += 1
                
        return count

    def identify_structural_element(self, text: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç"""
        text_lower = text.lower()
        
        for element, variants in self.structural_elements.items():
            if any(variant in text_lower for variant in variants):
                return element.upper()
                
        return None

    def count_exclusion_terms(self, text: str) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Ç–µ—Ä–º–∏–Ω—ã"""
        text_lower = text.lower()
        count = 0
        
        for category, terms in self.exclusion_terms.items():
            count += sum(1 for term in terms if term in text_lower)
                
        return count

    def is_valid_czech_context(self, text: str, threshold: int = 1) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —á–µ—à—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        concrete_count = self.count_concrete_terms(text)
        exclusion_count = self.count_exclusion_terms(text)
        
        # –õ–æ–≥–∏–∫–∞: –º–∏–Ω–∏–º—É–º threshold —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è –±–µ—Ç–æ–Ω–∞ –ò –Ω–µ –±–æ–ª–µ–µ 2 –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö
        return concrete_count >= threshold and exclusion_count <= 2

class ConcreteGradeValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –º–∞—Ä–æ–∫ –±–µ—Ç–æ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    
    def __init__(self, knowledge_base_path: str = "knowledge_base/complete-concrete-knowledge-base.json"):
        self.knowledge_base = self._load_knowledge_base(knowledge_base_path)
        self.valid_grades = self._extract_valid_grades()
        self.grade_mappings = self._build_grade_mappings()
        
    def _load_knowledge_base(self, path: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        try:
            if os.path.exists(path):
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}")
            
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return {
            "concrete_knowledge_base": {
                "strength_classes": {
                    "standard": {
                        "C8/10": {"cylinder": 8, "cube": 10},
                        "C12/15": {"cylinder": 12, "cube": 15},
                        "C16/20": {"cylinder": 16, "cube": 20},
                        "C20/25": {"cylinder": 20, "cube": 25},
                        "C25/30": {"cylinder": 25, "cube": 30},
                        "C30/37": {"cylinder": 30, "cube": 37},
                        "C35/45": {"cylinder": 35, "cube": 45},
                        "C40/50": {"cylinder": 40, "cube": 50},
                        "C45/55": {"cylinder": 45, "cube": 55},
                        "C50/60": {"cylinder": 50, "cube": 60}
                    }
                }
            }
        }

    def _extract_valid_grades(self) -> Set[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤–∞–ª–∏–¥–Ω—ã–µ –º–∞—Ä–∫–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        valid_grades = set()
        
        kb = self.knowledge_base.get('concrete_knowledge_base', {})
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–∞—Ä–∫–∏
        if 'strength_classes' in kb:
            classes = kb['strength_classes']
            if 'standard' in classes:
                valid_grades.update(classes['standard'].keys())
            if 'uhpc' in classes:
                valid_grades.update(classes['uhpc'].keys())
                
        # –õ–µ–≥–∫–∏–µ –±–µ—Ç–æ–Ω—ã
        if 'concrete_types_by_density' in kb:
            density_types = kb['concrete_types_by_density']
            for concrete_type, data in density_types.items():
                if 'strength_classes' in data:
                    if isinstance(data['strength_classes'], dict):
                        valid_grades.update(data['strength_classes'].keys())
                    elif isinstance(data['strength_classes'], list):
                        valid_grades.update(data['strength_classes'])
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(valid_grades)} –≤–∞–ª–∏–¥–Ω—ã—Ö –º–∞—Ä–æ–∫ –±–µ—Ç–æ–Ω–∞")
        return valid_grades

    def _build_grade_mappings(self) -> Dict[str, str]:
        """–°–æ–∑–¥–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –ø—Ä–æ—Å—Ç—ã—Ö –º–∞—Ä–æ–∫ –∫ –ø–æ–ª–Ω—ã–º"""
        mappings = {}
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        standard_mappings = {
            'C8': 'C8/10', 'C12': 'C12/15', 'C16': 'C16/20', 'C20': 'C20/25',
            'C25': 'C25/30', 'C30': 'C30/37', 'C35': 'C35/45', 'C40': 'C40/50',
            'C45': 'C45/55', 'C50': 'C50/60', 'C55': 'C55/67', 'C60': 'C60/75',
            'C70': 'C70/85', 'C80': 'C80/95', 'C90': 'C90/105', 'C100': 'C100/115'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –º–∞–ø–ø–∏–Ω–≥–∏, –≥–¥–µ —Ü–µ–ª–µ–≤–∞—è –º–∞—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ
        for simple, full in standard_mappings.items():
            if full in self.valid_grades:
                mappings[simple] = full
                
        return mappings

    def normalize_grade(self, grade: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –º–∞—Ä–∫—É –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"""
        grade = re.sub(r'\s+', '', grade.upper())
        return self.grade_mappings.get(grade, grade)

    def is_valid_grade(self, grade: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –º–∞—Ä–∫–∏"""
        normalized = self.normalize_grade(grade)
        return normalized in self.valid_grades

    def get_grade_info(self, grade: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–∞—Ä–∫–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        normalized = self.normalize_grade(grade)
        
        if not self.is_valid_grade(normalized):
            return {}
            
        kb = self.knowledge_base.get('concrete_knowledge_base', {})
        strength_classes = kb.get('strength_classes', {})
        
        # –ü–æ–∏—Å–∫ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–∞—Ä–∫–∞—Ö
        if 'standard' in strength_classes and normalized in strength_classes['standard']:
            return strength_classes['standard'][normalized]
            
        return {}

class ImprovedRegexEngine:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self, validator: ConcreteGradeValidator):
        self.validator = validator
        self.patterns = self._build_patterns()
        self.exclusion_patterns = self._build_exclusion_patterns()
        
    def _build_patterns(self) -> List[str]:
        """–°—Ç—Ä–æ–∏—Ç —Å—Ç—Ä–æ–≥–∏–µ regex-–ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        patterns = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –º–∞—Ä–∫–∞–º–∏
        if self.validator.valid_grades:
            escaped_grades = [re.escape(grade) for grade in self.validator.valid_grades]
            exact_pattern = '|'.join(escaped_grades)
            patterns.append(rf'\b({exact_pattern})\b')
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç C##/## —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        patterns.append(r'\bC([8-9]|[1-9][0-9]|1[0-7][0-9])/([1-9][0-9]|1[0-1][0-9])\b')
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –õ–µ–≥–∫–∏–µ –±–µ—Ç–æ–Ω—ã LC##/##
        patterns.append(r'\bLC([8-9]|[1-8][0-9])/([9]|[1-8][0-9])\b')
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 4: –ü—Ä–æ—Å—Ç—ã–µ –º–∞—Ä–∫–∏ C## (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω)
        patterns.append(r'\bC([8-9]|[1-9][0-9]|1[0-7][0-9])(?!/\d)\b')
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 5: –ú–∞—Ä–∫–∏ —Å –∫–ª–∞—Å—Å–∞–º–∏ —Å—Ä–µ–¥—ã
        patterns.append(r'\bC\d{1,2}/\d{1,2}(?:\s*[-‚Äì]?\s*X[CDFASM]\d*(?:\s*,\s*X[CDFASM]\d*)*)?(?:\s*[-‚Äì]?\s*X[CDFASM]\d*)*\b')
        
        return patterns
        
    def _build_exclusion_patterns(self) -> List[str]:
        """–ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–∫–ª—é—á–µ–Ω–∏–π"""
        return [
            r'C\d{4,}',                      # –î–ª–∏–Ω–Ω—ã–µ —á–∏—Å–ª–∞
            r'[Cc]z\d+',                     # CZ –∫–æ–¥—ã
            r'C\d+[A-Z]{3,}',               # –î–ª–∏–Ω–Ω—ã–µ –±—É–∫–≤–µ–Ω–Ω—ã–µ —Å—É—Ñ—Ñ–∏–∫—Å—ã
            r'\bC(?:ad|AD)\b',               # CAD
            r'\bC(?:o|O)\.?\s*\d+',         # –ù–æ–º–µ—Ä–∞ –∫–æ–º–ø–∞–Ω–∏–π
            r'C[A-Z]\d+[A-Z]',              # –°–º–µ—à–∞–Ω–Ω—ã–µ –∫–æ–¥—ã
            r'\bC\s?\d+\s?(?:kg|mm|cm|m|%)\b',  # –° –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
            r'\bC\d+[-_]\d+[-_]\d+',        # –í–µ—Ä—Å–∏–∏, –¥–∞—Ç—ã
        ]

    def find_matches(self, text: str) -> List[Tuple[str, int, int]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ"""
        matches = []
        seen_grades = set()
        
        for pattern in self.patterns:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                grade = match.group().strip().upper()
                start, end = match.span()
                
                # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                if grade in seen_grades:
                    continue
                    
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                if self._is_excluded(grade, text, start, end):
                    continue
                    
                matches.append((grade, start, end))
                seen_grades.add(grade)
                
        return matches

    def _is_excluded(self, grade: str, text: str, start: int, end: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏—è"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        for exclusion in self.exclusion_patterns:
            if re.search(exclusion, grade, re.IGNORECASE):
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (¬±300 —Å–∏–º–≤–æ–ª–æ–≤)
        context_start = max(0, start - 300)
        context_end = min(len(text), end + 300)
        context = text[context_start:context_end].lower()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ "–Ω–µ-–±–µ—Ç–æ–Ω–Ω—ã—Ö" —Ç–µ—Ä–º–∏–Ω–æ–≤
        exclusion_terms = [
            'str√°nka', 'strana', 'page', 'kapitola', 'odd√≠l',
            'k√≥d', 'ƒç√≠slo', 'number', 'firma', 'spoleƒçnost',
            'datum', 'date', 'cena', 'price', 'telefon', 'email'
        ]
        
        exclusion_count = sum(1 for term in exclusion_terms if term in context)
        return exclusion_count >= 3

class ConcreteAgentHybrid:
    """–ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ—Ç–æ–Ω–æ–≤"""
    
    def __init__(self, knowledge_base_path: str = "knowledge_base/complete-concrete-knowledge-base.json"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
        self.knowledge_base_path = knowledge_base_path
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.validator = ConcreteGradeValidator(knowledge_base_path)
        self.czech_processor = CzechLanguageProcessor()
        self.regex_engine = ImprovedRegexEngine(self.validator)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
        self.doc_parser = DocParser() if DocParser else None
        self.smeta_parser = SmetaParser() if SmetaParser else None
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.min_confidence_threshold = 0.6
        self.max_context_length = 500
        
        logger.info("ConcreteAgentHybrid –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def analyze_text(self, text: str, source_type: str = "document") -> AnalysisResult:
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
        start_time = time.time()
        
        try:
            # –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            raw_matches = self.regex_engine.find_matches(text)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
            validated_matches = []
            structural_elements = []
            
            for grade, start, end in raw_matches:
                match_result = self._process_match(text, grade, start, end)
                
                if match_result and match_result.confidence >= self.min_confidence_threshold:
                    validated_matches.append(match_result)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
                    element = self._extract_structural_element(match_result.context)
                    if element:
                        structural_elements.append(element)
            
            # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–æ—Ä–º–∞–º
            compliance_issues = self._check_compliance(validated_matches)
            recommendations = self._generate_recommendations(validated_matches, compliance_issues)
            
            # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            avg_confidence = sum(m.confidence for m in validated_matches) / len(validated_matches) if validated_matches else 0
            
            processing_time = time.time() - start_time
            
            return AnalysisResult(
                success=True,
                total_matches=len(validated_matches),
                analysis_method="improved_hybrid_regex_czech_validation",
                processing_time=processing_time,
                concrete_summary=[self._match_to_dict(m) for m in validated_matches],
                structural_elements=structural_elements,
                compliance_issues=compliance_issues,
                recommendations=recommendations,
                confidence_score=avg_confidence
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return AnalysisResult(
                success=False,
                total_matches=0,
                analysis_method="error",
                processing_time=time.time() - start_time,
                concrete_summary=[],
                structural_elements=[],
                compliance_issues=[f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"],
                recommendations=["–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∞–Ω–∞–ª–∏–∑"],
                confidence_score=0.0
            )

    def _process_match(self, text: str, grade: str, start: int, end: int) -> Optional[ConcreteMatch]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_start = max(0, start - 250)
        context_end = min(len(text), end + 250)
        context = text[context_start:context_end]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—à—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if not self.czech_processor.is_valid_czech_context(context):
            return None
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–∞—Ä–∫—É
        normalized_grade = self.validator.normalize_grade(grade)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        if not self.validator.is_valid_grade(normalized_grade):
            return None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
        structural_element = self.czech_processor.identify_structural_element(context)
        location = structural_element or "nespecifikov√°no"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∞—Å—Å –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
        exposure_class = self._extract_exposure_class(context)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = self._calculate_confidence(normalized_grade, context, structural_element, exposure_class)
        
        return ConcreteMatch(
            grade=normalized_grade,
            context=context.strip()[:self.max_context_length],
            location=location,
            confidence=confidence,
            method="hybrid_regex_czech",
            coordinates=None,
            structural_element=structural_element,
            exposure_class=exposure_class,
            position={"start": start, "end": end}
        )

    def _extract_exposure_class(self, context: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª–∞—Å—Å—ã –≤–æ–∑–¥–µ–π—Å—Ç–≤—É—é—â–µ–π —Å—Ä–µ–¥—ã"""
        exposure_pattern = r'X[CDFASM]\d*'
        matches = re.findall(exposure_pattern, context, re.IGNORECASE)
        return ', '.join(set(m.upper() for m in matches)) if matches else None

    def _calculate_confidence(self, grade: str, context: str, structural_element: Optional[str], 
                            exposure_class: Optional[str]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–∞—Ä–∫–µ"""
        confidence = 0.4  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        
        # –ë–æ–Ω—É—Å –∑–∞ –≤–∞–ª–∏–¥–Ω—É—é –º–∞—Ä–∫—É
        if self.validator.is_valid_grade(grade):
            confidence += 0.3
        
        # –ë–æ–Ω—É—Å –∑–∞ —á–µ—à—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        czech_terms_count = self.czech_processor.count_concrete_terms(context)
        confidence += min(czech_terms_count * 0.05, 0.25)
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
        if structural_element:
            confidence += 0.1
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–ª–∞—Å—Å –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
        if exposure_class:
            confidence += 0.1
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        tech_terms = ['mpa', 'pevnost', 'cement', 'norma', 'v√Ωroba', 'kvalita']
        context_lower = context.lower()
        tech_bonus = sum(0.02 for term in tech_terms if term in context_lower)
        confidence += min(tech_bonus, 0.15)
        
        return min(confidence, 1.0)

    def _extract_structural_element(self, context: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ"""
        element_type = self.czech_processor.identify_structural_element(context)
        
        if not element_type:
            return None
            
        return {
            "type": element_type,
            "context": context[:200],
            "requirements": self._get_element_requirements(element_type)
        }

    def _get_element_requirements(self, element_type: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        requirements = {
            "Z√ÅKLAD": ["Minim√°ln√≠ t≈ô√≠da C16/20", "Ochrana proti XA", "Kryt√≠ min 35mm"],
            "PIL√ç≈ò": ["Minim√°ln√≠ t≈ô√≠da C20/25", "Vhodnost pro XC prost≈ôed√≠"],
            "STƒöNA": ["Minim√°ln√≠ t≈ô√≠da C16/20", "Ochrana proti XC"],
            "DESKA": ["Minim√°ln√≠ t≈ô√≠da C20/25", "Ochrana proti XC"],
        }
        
        return requirements.get(element_type, ["Kontrola dle ƒåSN EN 206"])

    def _check_compliance(self, matches: List[ConcreteMatch]) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ—Ä–º–∞–º"""
        issues = []
        
        for match in matches:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—á–Ω–æ—Å—Ç—å
            if match.grade.startswith('C'):
                try:
                    strength = int(match.grade.split('/')[0][1:])
                    if strength < 12:
                        issues.append(f"–ú–∞—Ä–∫–∞ {match.grade} –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π C12/15")
                except:
                    pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            if match.structural_element == "Z√ÅKLAD" and match.grade in ["C8/10", "C12/15"]:
                issues.append(f"–î–ª—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º C16/20, –Ω–∞–π–¥–µ–Ω–æ {match.grade}")
        
        return issues

    def _generate_recommendations(self, matches: List[ConcreteMatch], issues: List[str]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendations = []
        
        if not matches:
            recommendations.append("–ú–∞—Ä–∫–∏ –±–µ—Ç–æ–Ω–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.")
            return recommendations
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if len(matches) > 5:
            recommendations.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö –º–∞—Ä–æ–∫. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é.")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
        exposure_classes = [m.exposure_class for m in matches if m.exposure_class]
        if not any(exposure_classes):
            recommendations.append("–£–∫–∞–∂–∏—Ç–µ –∫–ª–∞—Å—Å—ã –≤–æ–∑–¥–µ–π—Å—Ç–≤—É—é—â–µ–π —Å—Ä–µ–¥—ã (XC, XF, XA –∏ —Ç.–¥.)")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º
        elements = [m.structural_element for m in matches if m.structural_element]
        if not any(elements):
            recommendations.append("–£—Ç–æ—á–Ω–∏—Ç–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –±–µ—Ç–æ–Ω–∞ –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö")
        
        return recommendations

    def _match_to_dict(self, match: ConcreteMatch) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç ConcreteMatch –≤ —Å–ª–æ–≤–∞—Ä—å"""
        result = asdict(match)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        grade_info = self.validator.get_grade_info(match.grade)
        if grade_info:
            result["grade_properties"] = grade_info
        
        return result

    def analyze_document(self, file_path: str) -> AnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç"""
        try:
            if self.doc_parser:
                text = self.doc_parser.parse(file_path)
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ —á—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            return self.analyze_text(text, source_type="document")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {file_path}: {e}")
            return AnalysisResult(
                success=False,
                total_matches=0,
                analysis_method="document_analysis_error",
                processing_time=0,
                concrete_summary=[],
                structural_elements=[],
                compliance_issues=[f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}"],
                recommendations=["–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏ —Ñ–æ—Ä–º–∞—Ç"],
                confidence_score=0.0
            )

    def analyze_smeta(self, file_path: str) -> AnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–º–µ—Ç—É"""
        try:
            if self.smeta_parser:
                data = self.smeta_parser.parse(file_path)
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ —Å–º–µ—Ç—ã
                text = " ".join(str(value) for value in data.values() if isinstance(value, (str, int, float)))
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ —á—Ç–µ–Ω–∏–µ
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            return self.analyze_text(text, source_type="smeta")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–º–µ—Ç—ã {file_path}: {e}")
            return AnalysisResult(
                success=False,
                total_matches=0,
                analysis_method="smeta_analysis_error", 
                processing_time=0,
                concrete_summary=[],
                structural_elements=[],
                compliance_issues=[f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å–º–µ—Ç—ã: {str(e)}"],
                recommendations=["–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ —Å–º–µ—Ç—ã"],
                confidence_score=0.0
            )

    def generate_report(self, result: AnalysisResult, output_path: str = None) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç"""
        report = {
            "analysis_metadata": {
                "timestamp": datetime.now().isoformat(),
                "agent_version": "2.0_improved",
                "knowledge_base": self.knowledge_base_path,
                "success": result.success,
                "processing_time": result.processing_time,
                "total_matches": result.total_matches,
                "confidence_score": result.confidence_score
            },
            "concrete_analysis": {
                "method": result.analysis_method,
                "matches": result.concrete_summary,
                "unique_grades": list(set(m["grade"] for m in result.concrete_summary)),
                "grade_frequency": self._calculate_grade_frequency(result.concrete_summary)
            },
            "structural_analysis": {
                "elements": result.structural_elements,
                "element_types": list(set(e.get("type", "nespecifikov√°no") for e in result.structural_elements))
            },
            "compliance_check": {
                "issues": result.compliance_issues,
                "recommendations": result.recommendations,
                "compliance_score": max(0, 1.0 - len(result.compliance_issues) * 0.2)
            },
            "statistics": {
                "avg_confidence": result.confidence_score,
                "high_confidence_matches": len([m for m in result.concrete_summary if m.get("confidence", 0) > 0.8]),
                "with_exposure_class": len([m for m in result.concrete_summary if m.get("exposure_class")]),
                "with_structural_element": len([m for m in result.concrete_summary if m.get("structural_element")])
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
        if output_path:
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
                logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
        
        return report

    def _calculate_grade_frequency(self, matches: List[Dict[str, Any]]) -> Dict[str, int]:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É –º–∞—Ä–æ–∫"""
        frequency = {}
        for match in matches:
            grade = match.get("grade", "unknown")
            frequency[grade] = frequency.get(grade, 0) + 1
        return frequency

    # –ú–µ—Ç–æ–¥—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º API
    def analyze(self, text: str) -> Dict[str, Any]:
        """–ú–µ—Ç–æ–¥ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º API"""
        result = self.analyze_text(text)
        
        return {
            "success": result.success,
            "total_matches": result.total_matches,
            "analysis_method": result.analysis_method,
            "concrete_summary": result.concrete_summary,
            "confidence_score": result.confidence_score,
            "processing_time": result.processing_time
        }

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
import time
from datetime import datetime

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º API
def analyze_concrete_improved(text: str, knowledge_base_path: str = None) -> Dict[str, Any]:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ—Ç–æ–Ω–∞ - –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if knowledge_base_path is None:
        knowledge_base_path = "knowledge_base/complete-concrete-knowledge-base.json"
    
    agent = ConcreteAgentHybrid(knowledge_base_path)
    return agent.analyze(text)

def create_concrete_agent(knowledge_base_path: str = None) -> ConcreteAgentHybrid:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    if knowledge_base_path is None:
        knowledge_base_path = "knowledge_base/complete-concrete-knowledge-base.json"
    
    return ConcreteAgentHybrid(knowledge_base_path)

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    test_text = """
    Z√°kladov√° konstrukce bude provedena z betonu t≈ô√≠dy C25/30 XC1, XA1.
    Stƒõnov√© konstrukce budou z betonu C30/37 XF2.
    Pro pil√≠≈ôe se pou≈æije beton LC25/28.
    
    Neplatn√© k√≥dy: C425, CZ75994234, str√°nka 125.
    Spoleƒçnost ABC s.r.o. dod√° materi√°l podle normy ƒåSN EN 206.
    
    Vƒõnec bude betonov√°n betonem t≈ô√≠dy C20/25 s cementem CEM I 42.5 R.
    Deska gar√°≈æe vy≈æaduje beton C30/37 XF4 kv≈Øli zmrazovac√≠m cykl≈Øm.
    """
    
    print("üß± TESTOV√ÅN√ç VYLEP≈†EN√âHO CONCRETE AGENT")
    print("=" * 60)
    
    # Vytvo≈ôen√≠ agenta
    agent = create_concrete_agent()
    
    # Anal√Ωza textu
    result = agent.analyze_text(test_text)
    
    print(f"‚úÖ √öspƒõch: {result.success}")
    print(f"üìä Nalezeno marky: {result.total_matches}")
    print(f"‚ö° Doba zpracov√°n√≠: {result.processing_time:.3f}s")
    print(f"üéØ Celkov√° jistota: {result.confidence_score:.2f}")
    print()
    
    print("üîç NALEZEN√â MARKY:")
    for i, match in enumerate(result.concrete_summary, 1):
        print(f"{i:2d}. {match['grade']:8s} | {match['location']:15s} | {match['confidence']:.2f} | {match.get('exposure_class', 'N/A')}")
    
    print()
    print("üèóÔ∏è KONSTRUKƒåN√ç PRVKY:")
    for element in result.structural_elements:
        print(f"   - {element.get('type', 'N/A')}: {element.get('requirements', ['N/A'])[0]}")
    
    print()
    print("‚ö†Ô∏è PROBL√âMY A DOPORUƒåEN√ç:")
    for issue in result.compliance_issues:
        print(f"   ‚ùå {issue}")
    for rec in result.recommendations:
        print(f"   üí° {rec}")
    
    print()
    print("üìã GENEROV√ÅN√ç PODROBN√âHO REPORTU...")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
    report = agent.generate_report(result, "concrete_analysis_report.json")
    print(f"‚úÖ Podrobn√Ω report ulo≈æen jako 'concrete_analysis_report.json'")
    print(f"üìà Statistiky: {report['statistics']}")
