"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π ConcreteAgentHybrid ‚Äî –∞–≥–µ–Ω—Ç –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–µ—Ç–æ–Ω–æ–≤.
"""

import re
import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

from parsers.doc_parser import DocParser
from parsers.smeta_parser import SmetaParser
from utils.claude_client import get_claude_client
from config.settings import settings
from outputs.save_report import save_merged_report

logger = logging.getLogger(__name__)

@dataclass
class ConcreteMatch:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω–æ–π –º–∞—Ä–∫–∏ –±–µ—Ç–æ–Ω–∞"""
    grade: str
    context: str
    location: str
    confidence: float
    method: str
    coordinates: Optional[Tuple[int, int, int, int]] = None

@dataclass 
class StructuralElement:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞"""
    name: str
    concrete_grade: Optional[str]
    location: str
    context: str

class ConcreteAgentHybrid:
    def __init__(self, knowledge_base_path="knowledge_base/complete-concrete-knowledge-base.json"):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        try:
            with open(knowledge_base_path, "r", encoding="utf-8") as f:
                self.knowledge_base = json.load(f)
            logger.info("üìö Knowledge-base –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å knowledge-base: {e}")
            self.knowledge_base = self._create_default_kb()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –º–∞—Ä–∫–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        self.allowed_grades = set(self._extract_valid_grades_from_kb(self.knowledge_base))
        logger.info(f"üéØ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.allowed_grades)} –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –º–∞—Ä–æ–∫ –±–µ—Ç–æ–Ω–∞")

        self.doc_parser = DocParser()
        self.smeta_parser = SmetaParser()
        self.claude_client = get_claude_client() if settings.is_claude_enabled() else None

        # –°—Ç—Ä–æ–≥–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞—Ä–æ–∫ –±–µ—Ç–æ–Ω–∞ (—Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã)
        self.concrete_pattern = r'\b(?:LC|C)\d{1,3}/\d{1,3}\b'

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (—á–µ—à—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã)
        self.context_keywords = [
            'beton', 'betonu', 'betonem', 'betony', 'betonov√©', 'betonov√Ωch',
            't≈ô√≠da', 't≈ô√≠dy', 't≈ô√≠du', 't≈ô√≠dƒõ',
            'stupe≈à', 'stupnƒõ', 'stupni',
            'odolnost', 'odolnosti',
            'pevnost', 'pevnosti',
            'XC1', 'XC2', 'XC3', 'XC4',
            'XA1', 'XA2', 'XA3',
            'XF1', 'XF2', 'XF3', 'XF4',
            'XD1', 'XD2', 'XD3',
            'XM1', 'XM2', 'XM3'
        ]

        # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—á–µ—à—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã)
        self.structural_elements = {
            'OPƒöRA': {'en': 'abutment', 'applications': ['XC4', 'XD1', 'XF2']},
            'PIL√ç≈ò': {'en': 'pier', 'applications': ['XC4', 'XD3', 'XF4']},
            '≈ò√çMSA': {'en': 'cornice', 'applications': ['XC4', 'XD3', 'XF4']},
            'MOSTOVKA': {'en': 'deck', 'applications': ['XC4', 'XD3', 'XF4']},
            'Z√ÅKLAD': {'en': 'foundation', 'applications': ['XC1', 'XC2', 'XA1']},
            'VOZOVKA': {'en': 'roadway', 'applications': ['XF2', 'XF4', 'XD1']},
            'GAR√Å≈Ω': {'en': 'garage', 'applications': ['XD1']},
            'STƒöNA': {'en': 'wall', 'applications': ['XC1', 'XC3', 'XC4']},
            'SLOUP': {'en': 'column', 'applications': ['XC1', 'XC3']},
            'SCHODI≈†Tƒö': {'en': 'stairs', 'applications': ['XC1', 'XC3']},
            'PODKLADN√ç': {'en': 'subgrade', 'applications': ['X0', 'XC1']},
            'NOSN√Å': {'en': 'load-bearing', 'applications': ['XC1', 'XC3']},
            'VƒöNEC': {'en': 'tie-beam', 'applications': ['XC2', 'XF1']},
            'DESKA': {'en': 'slab', 'applications': ['XC1', 'XC2']},
            'PREFABRIK√ÅT': {'en': 'precast', 'applications': ['XC1', 'XC3']},
            'MONOLITICK√ù': {'en': 'monolithic', 'applications': ['XC1', 'XC2']},
        }

        # –ö–æ–¥—ã —Å–º–µ—Ç –∏ –∏—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        self.smeta_codes = {
            '801': 'Prost√Ω beton',
            '802': '≈Ωelezobeton monolitick√Ω',
            '803': '≈Ωelezobeton prefabrikovan√Ω',
            '811': 'Betony speci√°ln√≠',
            '271': 'Konstrukce betonov√© a ≈æelezobetonov√©',
            'HSV': 'Hlavn√≠ stavebn√≠ v√Ωroba',
            'PSV': 'P≈ôidru≈æen√° stavebn√≠ v√Ωroba',
        }

    def _extract_valid_grades_from_kb(self, kb: Dict) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –º–∞—Ä–∫–∏ –±–µ—Ç–æ–Ω–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        grades = []
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã –ø—Ä–æ—á–Ω–æ—Å—Ç–∏
        standard_classes = kb.get("strength_classes", {}).get("standard", {})
        if standard_classes:
            grades.extend(standard_classes.keys())
        
        # UHPC –∫–ª–∞—Å—Å—ã
        uhpc_classes = kb.get("strength_classes", {}).get("uhpc", {})
        if uhpc_classes:
            grades.extend(uhpc_classes.keys())
        
        # –õ–µ–≥–∫–∏–π –±–µ—Ç–æ–Ω
        lightweight_classes = kb.get("concrete_types_by_density", {}).get("lehk√Ω_beton", {}).get("strength_classes", [])
        if lightweight_classes:
            grades.extend(lightweight_classes)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ –º–∞—Ä–∫–∏
        normalized_grades = []
        for grade in grades:
            normalized = self._normalize_concrete_grade(grade)
            if normalized and self._is_valid_grade_format(normalized):
                normalized_grades.append(normalized)
        
        return normalized_grades

    def _create_default_kb(self) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            "strength_classes": {
                "standard": {
                    "C12/15": {"fck": 12, "fcm": 20},
                    "C16/20": {"fck": 16, "fcm": 24},
                    "C20/25": {"fck": 20, "fcm": 28},
                    "C25/30": {"fck": 25, "fcm": 33},
                    "C30/37": {"fck": 30, "fcm": 38},
                    "C35/45": {"fck": 35, "fcm": 43},
                    "C40/50": {"fck": 40, "fcm": 48},
                    "C45/55": {"fck": 45, "fcm": 53},
                    "C50/60": {"fck": 50, "fcm": 58}
                },
                "uhpc": {
                    "C80/95": {"fck": 80, "fcm": 88},
                    "C90/105": {"fck": 90, "fcm": 98}
                }
            },
            "concrete_types_by_density": {
                "lehk√Ω_beton": {
                    "strength_classes": ["LC12/13", "LC16/18", "LC20/22", "LC25/28", "LC30/33", "LC35/38", "LC40/44", "LC45/50", "LC50/55", "LC55/60", "LC60/66", "LC70/77", "LC80/88"]
                }
            },
            "environment_classes": {
                "XC1": {"description": "such√© nebo st√°le mokr√©", "applications": ["interi√©r", "z√°klady"]},
                "XC2": {"description": "mokr√©, obƒças such√©", "applications": ["z√°klady", "spodn√≠ stavba"]},
                "XC3": {"description": "st≈ôednƒõ mokr√©", "applications": ["kryt√© prostory"]},
                "XC4": {"description": "st≈ô√≠davƒõ mokr√© a such√©", "applications": ["vnƒõj≈°√≠ povrchy"]},
                "XD1": {"description": "chloridy - m√≠rn√©", "applications": ["gar√°≈æe", "parkovi≈°tƒõ"]},
                "XD3": {"description": "chloridy - siln√©", "applications": ["mosty", "vozovky"]},
                "XF1": {"description": "mr√°z - m√≠rn√Ω", "applications": ["vnƒõj≈°√≠ svisl√© plochy"]},
                "XF2": {"description": "mr√°z + soli", "applications": ["silniƒçn√≠ konstrukce"]},
                "XF4": {"description": "mr√°z + soli - extr√©mn√≠", "applications": ["mostovky", "vozovky"]},
                "XA1": {"description": "chemicky agresivn√≠ - slabƒõ", "applications": ["z√°klady", "septiky"]},
            }
        }

    def _is_valid_grade_format(self, grade: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –º–∞—Ä–∫–∏ –±–µ—Ç–æ–Ω–∞"""
        if not grade or len(grade) > 8:
            return False
        
        if '/' not in grade:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ —á–∏—Å–ª–∞
        if re.match(r'C\d{4,}', grade):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if not re.match(r'^(?:LC|C)\d{1,3}/\d{1,3}$', grade):
            return False
        
        return True

    def _has_concrete_context(self, text: str, start_pos: int, end_pos: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤ —Ä—è–¥–æ–º —Å –º–∞—Ä–∫–æ–π –±–µ—Ç–æ–Ω–∞"""
        context_window = 50
        context_start = max(0, start_pos - context_window)
        context_end = min(len(text), end_pos + context_window)
        context = text[context_start:context_end].lower()
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤
        keywords_pattern = '|'.join(re.escape(keyword.lower()) for keyword in self.context_keywords)
        
        return bool(re.search(rf'\b({keywords_pattern})\b', context, re.IGNORECASE))

    def _local_concrete_analysis(self, text: str) -> Dict[str, Any]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–æ–∫ –±–µ—Ç–æ–Ω–∞"""
        all_matches = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–≥–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞—Ä–æ–∫
        for match in re.finditer(self.concrete_pattern, text, re.IGNORECASE):
            grade = self._normalize_concrete_grade(match.group().strip())
            
            # –§–∏–ª—å—Ç—Ä 1: –ú–∞—Ä–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ whitelist –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            if grade not in self.allowed_grades:
                continue
            
            start_pos, end_pos = match.start(), match.end()
            
            # –§–∏–ª—å—Ç—Ä 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)
            if not self._has_concrete_context(text, start_pos, end_pos):
                continue
            
            # –§–∏–ª—å—Ç—Ä 3: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
            if not self._is_valid_grade_format(grade):
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            context_window = 100
            context_start = max(0, start_pos - context_window)
            context_end = min(len(text), end_pos + context_window)
            context = text[context_start:context_end]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            location = self._identify_structural_element(context)
            
            all_matches.append(ConcreteMatch(
                grade=grade,
                context=context.strip(),
                location=location,
                confidence=0.95,  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è —Å—Ç—Ä–æ–≥–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                method='regex_enhanced',
                coordinates=None
            ))
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª—É—á—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        unique_matches = {}
        for match in all_matches:
            key = match.grade
            if key not in unique_matches or match.confidence > unique_matches[key].confidence:
                unique_matches[key] = match
        
        return {
            'concrete_summary': [
                {
                    'grade': match.grade,
                    'location': match.location,
                    'context': match.context[:200],
                    'confidence': match.confidence,
                    'method': match.method
                }
                for match in unique_matches.values()
            ],
            'analysis_method': 'local_enhanced',
            'total_matches': len(unique_matches),
            'success': True,
            'allowed_grades_count': len(self.allowed_grades)
        }

    def _normalize_concrete_grade(self, grade: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ –º–∞—Ä–∫–∏ –±–µ—Ç–æ–Ω–∞"""
        if not grade:
            return ""
        
        # –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        normalized = grade.upper().strip().replace(" ", "")
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        normalized = re.sub(r'[^\w/]', '', normalized)
        
        return normalized

    def _identify_structural_element(self, context: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        context_upper = context.upper()
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        for element, info in self.structural_elements.items():
            if element in context_upper:
                return f"{element} ({info['en']})"
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        for element, info in self.structural_elements.items():
            if any(part in context_upper for part in element.split()):
                return f"{element} ({info['en']}) - —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ"
        
        return "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"

    async def _claude_concrete_analysis(self, text: str, smeta_data: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Claude —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        if not self.claude_client:
            return {"success": False, "error": "Claude client not available"}
        
        try:
            result = await self.claude_client.analyze_concrete_with_claude(text, smeta_data)
            
            return {
                'concrete_summary': result.get('claude_analysis', {}).get('concrete_grades', []),
                'analysis_method': 'claude_enhanced',
                'success': True,
                'tokens_used': result.get('tokens_used', 0),
                'raw_response': result.get('raw_response', '')
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Claude –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {"success": False, "error": str(e)}

    async def analyze(self, doc_paths: List[str], smeta_path: Optional[str] = None,
                      use_claude: bool = True, claude_mode: str = "enhancement") -> Dict[str, Any]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        """
        logger.info(f"üèóÔ∏è –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (—Ä–µ–∂–∏–º: {claude_mode})")
        
        all_text = ""
        processed_docs = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        for doc_path in doc_paths:
            try:
                text = self.doc_parser.parse(doc_path)
                all_text += text + "\n"
                
                processed_docs.append({
                    'file': Path(doc_path).name,
                    'type': 'Document',
                    'text_length': len(text)
                })
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {doc_path}: {e}")
                processed_docs.append({'file': Path(doc_path).name, 'error': str(e)})
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–º–µ—Ç—É
        smeta_data = []
        if smeta_path:
            try:
                smeta_result = self.smeta_parser.parse(smeta_path)
                smeta_data = smeta_result.get('items', [])
                logger.info(f"üìä –°–º–µ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {len(smeta_data)} –ø–æ–∑–∏—Ü–∏–π")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–º–µ—Ç—ã: {e}")
        
        # –õ–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Ç–µ–ø–µ—Ä—å —É–ª—É—á—à–µ–Ω–Ω—ã–π)
        local_result = self._local_concrete_analysis(all_text)
        
        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Claude
        final_result = local_result.copy()
        
        if use_claude and self.claude_client:
            claude_result = await self._claude_concrete_analysis(all_text, smeta_data)
            
            if claude_mode == "primary" and claude_result.get("success"):
                final_result = claude_result
            elif claude_mode == "enhancement" and claude_result.get("success"):
                final_result.update({
                    'claude_analysis': claude_result,
                    'analysis_method': 'hybrid_enhanced',
                    'total_tokens_used': claude_result.get('tokens_used', 0)
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        final_result.update({
            'processed_documents': processed_docs,
            'smeta_items': len(smeta_data),
            'processing_time': 'completed',
            'knowledge_base_version': '3.0'
        })
        
        return final_result

# ==============================
# üîß –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ==============================

_hybrid_agent = None

def get_hybrid_agent() -> ConcreteAgentHybrid:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    global _hybrid_agent
    if _hybrid_agent is None:
        _hybrid_agent = ConcreteAgentHybrid()
        logger.info("ü§ñ ConcreteAgentHybrid –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    return _hybrid_agent

# ==============================
# üöÄ API-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ==============================

async def analyze_concrete(doc_paths: List[str], smeta_path: Optional[str] = None,
                           use_claude: bool = True, claude_mode: str = "enhancement") -> Dict[str, Any]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ—Ç–æ–Ω–∞ - —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º API
    """
    agent = get_hybrid_agent()
    
    try:
        result = await agent.analyze(doc_paths, smeta_path, use_claude, claude_mode)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        try:
            save_merged_report(result, "outputs/concrete_analysis_report.json")
            logger.info("üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ outputs/concrete_analysis_report.json")
        except Exception in e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç: {e}")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ analyze_concrete: {e}")
        return {
            "error": str(e),
            "success": False,
            "analysis_method": "error",
            "concrete_summary": []
        }
