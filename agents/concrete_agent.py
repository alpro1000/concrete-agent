"""
ğŸ§± ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ConcreteAgentHybrid - Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ñ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
Ğ ĞµÑˆĞ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
1. Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²ÑĞµĞ³Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° "C"
2. ĞŸĞ»Ğ¾Ñ…Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‡ĞµÑˆÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°
3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ²ÑÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
"""

import re
import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ¸Ğ· Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
try:
    from parsers.doc_parser import DocParser
    from parsers.smeta_parser import SmetaParser
    from utils.claude_client import get_claude_client
    from config.settings import settings
    from outputs.save_report import save_merged_report
except ImportError:
    print("âš ï¸ ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾Ğ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ")
    DocParser = None
    SmetaParser = None

logger = logging.getLogger(__name__)

@dataclass
class ConcreteMatch:
    """Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ°Ñ€ĞºĞ¸ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ°"""
    grade: str
    context: str
    location: str
    confidence: float
    method: str
    coordinates: Optional[Tuple[int, int, int, int]] = None
    structural_element: Optional[str] = None
    exposure_class: Optional[str] = None
    position: Optional[Dict[str, int]] = None

@dataclass
class StructuralElement:
    """Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°"""
    name: str
    concrete_grade: Optional[str]
    location: str
    context: str
    exposure_requirements: List[str]
    min_strength_required: Optional[str] = None

@dataclass
class AnalysisResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    success: bool
    total_matches: int
    analysis_method: str
    processing_time: float
    concrete_summary: List[Dict[str, Any]]
    structural_elements: List[Dict[str, Any]]
    compliance_issues: List[str]
    recommendations: List[str]
    confidence_score: float

class CzechLanguageProcessor:
    """ĞŸÑ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€ Ñ‡ĞµÑˆÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° Ğ´Ğ»Ñ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸"""
    
    def __init__(self):
        self.concrete_terms = {
            # Ğ‘ĞµÑ‚Ğ¾Ğ½ Ğ²Ğ¾ Ğ²ÑĞµÑ… ÑĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸ÑÑ…
            'beton': [
                'beton', 'betonu', 'betony', 'betonÅ¯', 'betonem', 'betonech',
                'betonovÃ¡', 'betonovÃ©', 'betonovÃ½', 'betonovou', 'betonovÃ½ch',
                'betonovÃ½m', 'betonami', 'betonÃ¡Å™skÃ½', 'betonÃ¡Å™skÃ©'
            ],
            # ĞšĞ»Ğ°ÑÑ/ÑÑ‚ĞµĞ¿ĞµĞ½ÑŒ
            'tÅ™Ã­da': [
                'tÅ™Ã­da', 'tÅ™Ã­dy', 'tÅ™Ã­dÄ›', 'tÅ™Ã­du', 'tÅ™Ã­dou', 'tÅ™Ã­dÃ¡ch', 
                'tÅ™Ã­dami', 'tÅ™Ã­d', 'tÅ™Ã­dÃ¡m', 'tÅ™Ã­dou'
            ],
            # Ğ¡Ñ‚ĞµĞ¿ĞµĞ½ÑŒ
            'stupeÅˆ': [
                'stupeÅˆ', 'stupnÄ›', 'stupni', 'stupnÄ›m', 'stupnÃ­ch', 
                'stupÅˆÅ¯', 'stupÅˆÅ¯m', 'stupni'
            ],
            # ĞŸÑ€Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
            'pevnost': [
                'pevnost', 'pevnosti', 'pevnostÃ­', 'pevnostem', 'pevnostech',
                'pevnostnÃ­', 'pevnostnÃ­m', 'pevnostnÃ­ch'
            ],
            # ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾
            'kvalita': [
                'kvalita', 'kvality', 'kvalitÄ›', 'kvalitou', 'kvalit', 
                'kvalitÃ¡ch', 'kvalitnÃ­', 'kvalitnÃ­m'
            ],
            # ĞšĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ
            'konstrukce': [
                'konstrukce', 'konstrukcÃ­', 'konstrukcÃ­m', 'konstrukcemi', 
                'konstrukcÃ­ch', 'konstrukÄnÃ­', 'konstrukÄnÃ­m'
            ],
            # Ğ¦ĞµĞ¼ĞµĞ½Ñ‚
            'cement': [
                'cement', 'cementu', 'cementy', 'cementÅ¯', 'cementem', 
                'cementech', 'cementovÃ½', 'cementovÃ©'
            ],
            # Ğ—Ğ°Ğ»Ğ¸Ğ²ĞºĞ°
            'betonÃ¡Å¾': [
                'betonÃ¡Å¾', 'betonÃ¡Å¾e', 'betonÃ¡Å¾i', 'betonÃ¡Å¾Ã­', 
                'betonovÃ¡nÃ­', 'betonovat'
            ],
            # Ğ¡Ğ¼ĞµÑÑŒ
            'smÄ›s': [
                'smÄ›s', 'smÄ›si', 'smÄ›sÃ­', 'smÄ›sem', 'smÄ›sÃ­ch', 
                'smÄ›sovÃ½', 'smÄ›sovÃ©'
            ],
            # ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾
            'vÃ½roba': [
                'vÃ½roba', 'vÃ½roby', 'vÃ½robÄ›', 'vÃ½robu', 'vÃ½robou',
                'vÃ½robnÃ­', 'vÃ½robnÃ­k', 'vyrÃ¡bÄ›t'
            ]
        }
        
        self.structural_elements = {
            'zÃ¡klad': ['zÃ¡klad', 'zÃ¡klady', 'zÃ¡kladÅ¯', 'zÃ¡kladem', 'zÃ¡kladnÃ­', 'zÃ¡kladovÃ¡'],
            'pilÃ­Å™': ['pilÃ­Å™', 'pilÃ­Å™e', 'pilÃ­Å™Å¯', 'pilÃ­Å™em', 'pilÃ­Å™i'],
            'sloup': ['sloup', 'sloupy', 'sloupÅ¯', 'sloupem', 'sloupu'],
            'stÄ›na': ['stÄ›na', 'stÄ›ny', 'stÄ›n', 'stÄ›nou', 'stÄ›nÄ›'],
            'deska': ['deska', 'desky', 'desek', 'deskou', 'desce'],
            'nosnÃ­k': ['nosnÃ­k', 'nosnÃ­ky', 'nosnÃ­kÅ¯', 'nosnÃ­kem', 'nosnÃ­ku'],
            'vÄ›nec': ['vÄ›nec', 'vÄ›nce', 'vÄ›ncÅ¯', 'vÄ›ncem', 'vÄ›nci'],
            'schodiÅ¡tÄ›': ['schodiÅ¡tÄ›', 'schodiÅ¡Å¥', 'schodiÅ¡tÄ›m', 'schodiÅ¡ti'],
            'mostovka': ['mostovka', 'mostovky', 'mostovkou', 'mostovce'],
            'vozovka': ['vozovka', 'vozovky', 'vozovkou', 'vozovce'],
            'garÃ¡Å¾': ['garÃ¡Å¾', 'garÃ¡Å¾e', 'garÃ¡Å¾Ã­', 'garÃ¡Å¾ou', 'garÃ¡Å¾Ã­ch'],
            'Å™Ã­ms': ['Å™Ã­ms', 'Å™Ã­msa', 'Å™Ã­msy', 'Å™Ã­msou', 'Å™Ã­msÃ¡ch']
        }

        self.exclusion_terms = {
            # ĞĞ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ
            'admin': ['strÃ¡nka', 'strana', 'str.', 'page', 'kapitola', 'oddÃ­l', 'ÄÃ¡st', 'section'],
            # ĞšĞ¾Ğ´Ñ‹ Ğ¸ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ°  
            'codes': ['kÃ³d', 'ÄÃ­slo', 'number', 'id', 'identifikÃ¡tor', 'oznaÄenÃ­'],
            # ĞšĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸
            'companies': ['firma', 'spoleÄnost', 'company', 'spol.', 's.r.o.', 'a.s.'],
            # Ğ”Ğ°Ñ‚Ñ‹ Ğ¸ Ğ²Ñ€ĞµĞ¼Ñ
            'dates': ['datum', 'date', 'rok', 'year', 'mÄ›sÃ­c', 'month', 'den', 'day'],
            # Ğ¦ĞµĞ½Ñ‹ Ğ¸ Ğ´ĞµĞ½ÑŒĞ³Ğ¸
            'money': ['cena', 'price', 'cost', 'kÄ', 'koruna', 'euro', 'eur'],
            # ĞšĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹
            'contacts': ['telefon', 'tel', 'phone', 'email', 'adresa', 'address']
        }

    def count_concrete_terms(self, text: str) -> int:
        """ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ°"""
        text_lower = text.lower()
        count = 0
        
        for category, terms in self.concrete_terms.items():
            found = any(term in text_lower for term in terms)
            if found:
                count += 1
                
        return count

    def identify_structural_element(self, text: str) -> Optional[str]:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚"""
        text_lower = text.lower()
        
        for element, variants in self.structural_elements.items():
            if any(variant in text_lower for variant in variants):
                return element.upper()
                
        return None

    def count_exclusion_terms(self, text: str) -> int:
        """ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸ÑĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ğµ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ñ‹"""
        text_lower = text.lower()
        count = 0
        
        for category, terms in self.exclusion_terms.items():
            count += sum(1 for term in terms if term in text_lower)
                
        return count

    def is_valid_czech_context(self, text: str, threshold: int = 1) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‡ĞµÑˆÑĞºĞ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°"""
        concrete_count = self.count_concrete_terms(text)
        exclusion_count = self.count_exclusion_terms(text)
        
        # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°: Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ threshold Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ˜ Ğ½Ğµ Ğ±Ğ¾Ğ»ĞµĞµ 2 Ğ¸ÑĞºĞ»ÑÑ‡Ğ°ÑÑ‰Ğ¸Ñ…
        return concrete_count >= threshold and exclusion_count <= 2

class ConcreteGradeValidator:
    """Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€ Ğ¼Ğ°Ñ€Ğ¾Ğº Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹"""
    
    def __init__(self, knowledge_base_path: str = "knowledge_base/complete-concrete-knowledge-base.json"):
        self.knowledge_base = self._load_knowledge_base(knowledge_base_path)
        self.valid_grades = self._extract_valid_grades()
        self.grade_mappings = self._build_grade_mappings()
        
    def _load_knowledge_base(self, path: str) -> Dict[str, Any]:
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ±Ğ°Ğ·Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹"""
        try:
            if os.path.exists(path):
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ğ·Ñƒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: {e}")
            
        # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        return {
            "concrete_knowledge_base": {
                "strength_classes": {
                    "standard": {
                        "C8/10": {"cylinder": 8, "cube": 10},
                        "C12/15": {"cylinder": 12, "cube": 15},
                        "C16/20": {"cylinder": 16, "cube": 20},
                        "C20/25": {"cylinder": 20, "cube": 25},
                        "C25/30": {"cylinder": 25, "cube": 30},
                        "C30/37": {"cylinder": 30, "cube": 37},
                        "C35/45": {"cylinder": 35, "cube": 45},
                        "C40/50": {"cylinder": 40, "cube": 50},
                        "C45/55": {"cylinder": 45, "cube": 55},
                        "C50/60": {"cylinder": 50, "cube": 60}
                    }
                }
            }
        }

    def _extract_valid_grades(self) -> Set[str]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ²ÑĞµ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğµ Ğ¼Ğ°Ñ€ĞºĞ¸ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹"""
        valid_grades = set()
        
        kb = self.knowledge_base.get('concrete_knowledge_base', {})
        
        # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ°Ñ€ĞºĞ¸
        if 'strength_classes' in kb:
            classes = kb['strength_classes']
            if 'standard' in classes:
                valid_grades.update(classes['standard'].keys())
            if 'uhpc' in classes:
                valid_grades.update(classes['uhpc'].keys())
                
        # Ğ›ĞµĞ³ĞºĞ¸Ğµ Ğ±ĞµÑ‚Ğ¾Ğ½Ñ‹
        if 'concrete_types_by_density' in kb:
            density_types = kb['concrete_types_by_density']
            for concrete_type, data in density_types.items():
                if 'strength_classes' in data:
                    if isinstance(data['strength_classes'], dict):
                        valid_grades.update(data['strength_classes'].keys())
                    elif isinstance(data['strength_classes'], list):
                        valid_grades.update(data['strength_classes'])
        
        logger.info(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(valid_grades)} Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ€Ğ¾Ğº Ğ±ĞµÑ‚Ğ¾Ğ½Ğ°")
        return valid_grades

    def _build_grade_mappings(self) -> Dict[str, str]:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ¼Ğ°Ñ€Ğ¾Ğº Ğº Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼"""
        mappings = {}
        
        # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ
        standard_mappings = {
            'C8': 'C8/10', 'C12': 'C12/15', 'C16': 'C16/20', 'C20': 'C20/25',
            'C25': 'C25/30', 'C30': 'C30/37', 'C35': 'C35/45', 'C40': 'C40/50',
            'C45': 'C45/55', 'C50': 'C50/60', 'C55': 'C55/67', 'C60': 'C60/75',
            'C70': 'C70/85', 'C80': 'C80/95', 'C90': 'C90/105', 'C100': 'C100/115'
        }
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğµ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ¸, Ğ³Ğ´Ğµ Ñ†ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¼Ğ°Ñ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² Ğ±Ğ°Ğ·Ğµ
        for simple, full in standard_mappings.items():
            if full in self.valid_grades:
                mappings[simple] = full
                
        return mappings

    def normalize_grade(self, grade: str) -> str:
        """ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ Ğ¼Ğ°Ñ€ĞºÑƒ Ğº ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğ¼Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñƒ"""
        grade = re.sub(r'\s+', '', grade.upper())
        return self.grade_mappings.get(grade, grade)

    def is_valid_grade(self, grade: str) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ°Ñ€ĞºĞ¸"""
        normalized = self.normalize_grade(grade)
        return normalized in self.valid_grades

    def get_grade_info(self, grade: str) -> Dict[str, Any]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¼Ğ°Ñ€ĞºĞµ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹"""
        normalized = self.normalize_grade(grade)
        
        if not self.is_valid_grade(normalized):
            return {}
            
        kb = self.knowledge_base.get('concrete_knowledge_base', {})
        strength_classes = kb.get('strength_classes', {})
        
        # ĞŸĞ¾Ğ¸ÑĞº Ğ² ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ€ĞºĞ°Ñ…
        if 'standard' in strength_classes and normalized in strength_classes['standard']:
            return strength_classes['standard'][normalized]
            
        return {}

class ImprovedRegexEngine:
    """Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ²Ğ¸Ğ¶Ğ¾Ğº Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ñ‹Ñ… Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹"""
    
    def __init__(self, validator: ConcreteGradeValidator):
        self.validator = validator
        self.patterns = self._build_patterns()
        self.exclusion_patterns = self._build_exclusion_patterns()
        
    def _build_patterns(self) -> List[str]:
        """Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ñ‚ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¸Ğµ regex-Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹"""
        patterns = []
        
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ 1: Ğ¢Ğ¾Ñ‡Ğ½Ñ‹Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼Ğ¸ Ğ¼Ğ°Ñ€ĞºĞ°Ğ¼Ğ¸
        if self.validator.valid_grades:
            escaped_grades = [re.escape(grade) for grade in self.validator.valid_grades]
            exact_pattern = '|'.join(escaped_grades)
            patterns.append(rf'\b({exact_pattern})\b')
        
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ 2: Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ C##/## Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        patterns.append(r'\bC([8-9]|[1-9][0-9]|1[0-7][0-9])/([1-9][0-9]|1[0-1][0-9])\b')
        
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ 3: Ğ›ĞµĞ³ĞºĞ¸Ğµ Ğ±ĞµÑ‚Ğ¾Ğ½Ñ‹ LC##/##
        patterns.append(r'\bLC([8-9]|[1-8][0-9])/([9]|[1-8][0-9])\b')
        
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ 4: ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ¼Ğ°Ñ€ĞºĞ¸ C## (Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½)
        patterns.append(r'\bC([8-9]|[1-9][0-9]|1[0-7][0-9])(?!/\d)\b')
        
        # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½ 5: ĞœĞ°Ñ€ĞºĞ¸ Ñ ĞºĞ»Ğ°ÑÑĞ°Ğ¼Ğ¸ ÑÑ€ĞµĞ´Ñ‹
        patterns.append(r'\bC\d{1,2}/\d{1,2}(?:\s*[-â€“]?\s*X[CDFASM]\d*(?:\s*,\s*X[CDFASM]\d*)*)?(?:\s*[-â€“]?\s*X[CDFASM]\d*)*\b')
        
        return patterns
        
    def _build_exclusion_patterns(self) -> List[str]:
        """ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¹"""
        return [
            r'C\d{4,}',                      # Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ñ‡Ğ¸ÑĞ»Ğ°
            r'[Cc]z\d+',                     # CZ ĞºĞ¾Ğ´Ñ‹
            r'C\d+[A-Z]{3,}',               # Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ±ÑƒĞºĞ²ĞµĞ½Ğ½Ñ‹Ğµ ÑÑƒÑ„Ñ„Ğ¸ĞºÑÑ‹
            r'\bC(?:ad|AD)\b',               # CAD
            r'\bC(?:o|O)\.?\s*\d+',         # ĞĞ¾Ğ¼ĞµÑ€Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹
            r'C[A-Z]\d+[A-Z]',              # Ğ¡Ğ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ´Ñ‹
            r'\bC\s?\d+\s?(?:kg|mm|cm|m|%)\b',  # Ğ¡ ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†Ğ°Ğ¼Ğ¸ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ
            r'\bC\d+[-_]\d+[-_]\d+',        # Ğ’ĞµÑ€ÑĞ¸Ğ¸, Ğ´Ğ°Ñ‚Ñ‹
        ]

    def find_matches(self, text: str) -> List[Tuple[str, int, int]]:
        """ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ²ÑĞµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ"""
        matches = []
        seen_grades = set()
        
        for pattern in self.patterns:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                grade = match.group().strip().upper()
                start, end = match.span()
                
                # Ğ˜Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²
                if grade in seen_grades:
                    continue
                    
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ
                if self._is_excluded(grade, text, start, end):
                    continue
                    
                matches.append((grade, start, end))
                seen_grades.add(grade)
                
        return matches

    def _is_excluded(self, grade: str, text: str, start: int, end: int) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ"""
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¹
        for exclusion in self.exclusion_patterns:
            if re.search(exclusion, grade, re.IGNORECASE):
                return True
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Â±300 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)
        context_start = max(0, start - 300)
        context_end = min(len(text), end + 300)
        context = text[context_start:context_end].lower()
        
        # Ğ˜ÑĞºĞ»ÑÑ‡Ğ°ĞµĞ¼, ĞµÑĞ»Ğ¸ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ "Ğ½Ğµ-Ğ±ĞµÑ‚Ğ¾Ğ½Ğ½Ñ‹Ñ…" Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ²
        exclusion_terms = [
            'strÃ¡nka', 'strana', 'page', 'kapitola', 'oddÃ­l',
            'kÃ³d', 'ÄÃ­slo', 'number', 'firma', 'spoleÄnost',
            'datum', 'date', 'cena', 'price', 'telefon', 'email'
        ]
        
        exclusion_count = sum(1 for term in exclusion_terms if term in context)
        return exclusion_count >= 3

class ConcreteAgentHybrid:
    """ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ±ĞµÑ‚Ğ¾Ğ½Ğ¾Ğ²"""
    
    def __init__(self, knowledge_base_path: str = "knowledge_base/complete-concrete-knowledge-base.json"):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
        self.knowledge_base_path = knowledge_base_path
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
        self.validator = ConcreteGradeValidator(knowledge_base_path)
        self.czech_processor = CzechLanguageProcessor()
        self.regex_engine = ImprovedRegexEngine(self.validator)
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°Ñ€ÑĞµÑ€Ğ¾Ğ² (ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹)
        self.doc_parser = DocParser() if DocParser else None
        self.smeta_parser = SmetaParser() if SmetaParser else None
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
        self.min_confidence_threshold = 0.6
        self.max_context_length = 500
        
        logger.info("ConcreteAgentHybrid Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")

    def analyze_text(self, text: str, source_type: str = "document") -> AnalysisResult:
        """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ‚ĞµĞºÑÑ‚Ğ°"""
        start_time = time.time()
        
        try:
            # ĞŸĞ¾Ğ¸ÑĞº ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹
            raw_matches = self.regex_engine.find_matches(text)
            
            # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
            validated_matches = []
            structural_elements = []
            
            for grade, start, end in raw_matches:
                match_result = self._process_match(text, grade, start, end)
                
                if match_result and match_result.confidence >= self.min_confidence_threshold:
                    validated_matches.append(match_result)
                    
                    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚
                    element = self._extract_structural_element(match_result.context)
                    if element:
                        structural_elements.append(element)
            
            # ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ¼
            compliance_issues = self._check_compliance(validated_matches)
            recommendations = self._generate_recommendations(validated_matches, compliance_issues)
            
            # ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ Ğ¾Ğ±Ñ‰ĞµĞ¹ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
            avg_confidence = sum(m.confidence for m in validated_matches) / len(validated_matches) if validated_matches else 0
            
            processing_time = time.time() - start_time
            
            return AnalysisResult(
                success=True,
                total_matches=len(validated_matches),
                analysis_method="improved_hybrid_regex_czech_validation",
                processing_time=processing_time,
                concrete_summary=[self._match_to_dict(m) for m in validated_matches],
                structural_elements=structural_elements,
                compliance_issues=compliance_issues,
                recommendations=recommendations,
                confidence_score=avg_confidence
            )
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {e}")
            return AnalysisResult(
                success=False,
                total_matches=0,
                analysis_method="error",
                processing_time=time.time() - start_time,
                concrete_summary=[],
                structural_elements=[],
                compliance_issues=[f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {str(e)}"],
                recommendations=["ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ñ‚Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"],
                confidence_score=0.0
            )

    def _process_match(self, text: str, grade: str, start: int, end: int) -> Optional[ConcreteMatch]:
        """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ"""
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
        context_start = max(0, start - 250)
        context_end = min(len(text), end + 250)
        context = text[context_start:context_end]
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡ĞµÑˆÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
        if not self.czech_processor.is_valid_czech_context(context):
            return None
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ¼Ğ°Ñ€ĞºÑƒ
        normalized_grade = self.validator.normalize_grade(grade)
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ
        if not self.validator.is_valid_grade(normalized_grade):
            return None
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¼ĞµÑÑ‚Ğ¾Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ
        structural_element = self.czech_processor.identify_structural_element(context)
        location = structural_element or "nespecifikovÃ¡no"
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºĞ»Ğ°ÑÑ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
        exposure_class = self._extract_exposure_class(context)
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
        confidence = self._calculate_confidence(normalized_grade, context, structural_element, exposure_class)
        
        return ConcreteMatch(
            grade=normalized_grade,
            context=context.strip()[:self.max_context_length],
            location=location,
            confidence=confidence,
            method="hybrid_regex_czech",
            coordinates=None,
            structural_element=structural_element,
            exposure_class=exposure_class,
            position={"start": start, "end": end}
        )

    def _extract_exposure_class(self, context: str) -> Optional[str]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ĞºĞ»Ğ°ÑÑÑ‹ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¹ ÑÑ€ĞµĞ´Ñ‹"""
        exposure_pattern = r'X[CDFASM]\d*'
        matches = re.findall(exposure_pattern, context, re.IGNORECASE)
        return ', '.join(set(m.upper() for m in matches)) if matches else None

    def _calculate_confidence(self, grade: str, context: str, structural_element: Optional[str], 
                            exposure_class: Optional[str]) -> float:
        """Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµ"""
        confidence = 0.4  # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ
        
        # Ğ‘Ğ¾Ğ½ÑƒÑ Ğ·Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½ÑƒÑ Ğ¼Ğ°Ñ€ĞºÑƒ
        if self.validator.is_valid_grade(grade):
            confidence += 0.3
        
        # Ğ‘Ğ¾Ğ½ÑƒÑ Ğ·Ğ° Ñ‡ĞµÑˆÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
        czech_terms_count = self.czech_processor.count_concrete_terms(context)
        confidence += min(czech_terms_count * 0.05, 0.25)
        
        # Ğ‘Ğ¾Ğ½ÑƒÑ Ğ·Ğ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚
        if structural_element:
            confidence += 0.1
        
        # Ğ‘Ğ¾Ğ½ÑƒÑ Ğ·Ğ° ĞºĞ»Ğ°ÑÑ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
        if exposure_class:
            confidence += 0.1
        
        # Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ñ‹
        tech_terms = ['mpa', 'pevnost', 'cement', 'norma', 'vÃ½roba', 'kvalita']
        context_lower = context.lower()
        tech_bonus = sum(0.02 for term in tech_terms if term in context_lower)
        confidence += min(tech_bonus, 0.15)
        
        return min(confidence, 1.0)

    def _extract_structural_element(self, context: str) -> Optional[Dict[str, Any]]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğµ"""
        element_type = self.czech_processor.identify_structural_element(context)
        
        if not element_type:
            return None
            
        return {
            "type": element_type,
            "context": context[:200],
            "requirements": self._get_element_requirements(element_type)
        }

    def _get_element_requirements(self, element_type: str) -> List[str]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°"""
        requirements = {
            "ZÃKLAD": ["MinimÃ¡lnÃ­ tÅ™Ã­da C16/20", "Ochrana proti XA", "KrytÃ­ min 35mm"],
            "PILÃÅ˜": ["MinimÃ¡lnÃ­ tÅ™Ã­da C20/25", "Vhodnost pro XC prostÅ™edÃ­"],
            "STÄšNA": ["MinimÃ¡lnÃ­ tÅ™Ã­da C16/20", "Ochrana proti XC"],
            "DESKA": ["MinimÃ¡lnÃ­ tÅ™Ã­da C20/25", "Ochrana proti XC"],
        }
        
        return requirements.get(element_type, ["Kontrola dle ÄŒSN EN 206"])

    def _check_compliance(self, matches: List[ConcreteMatch]) -> List[str]:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ¼"""
        issues = []
        
        for match in matches:
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ¿Ñ€Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
            if match.grade.startswith('C'):
                try:
                    strength = int(match.grade.split('/')[0][1:])
                    if strength < 12:
                        issues.append(f"ĞœĞ°Ñ€ĞºĞ° {match.grade} Ğ½Ğ¸Ğ¶Ğµ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ C12/15")
                except:
                    pass
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°
            if match.structural_element == "ZÃKLAD" and match.grade in ["C8/10", "C12/15"]:
                issues.append(f"Ğ”Ğ»Ñ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ C16/20, Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {match.grade}")
        
        return issues

    def _generate_recommendations(self, matches: List[ConcreteMatch], issues: List[str]) -> List[str]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸"""
        recommendations = []
        
        if not matches:
            recommendations.append("ĞœĞ°Ñ€ĞºĞ¸ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ.")
            return recommendations
        
        # ĞĞ±Ñ‰Ğ¸Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
        if len(matches) > 5:
            recommendations.append("ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ€Ğ¾Ğº. Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ.")
        
        # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ»Ğ°ÑÑĞ°Ğ¼ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
        exposure_classes = [m.exposure_class for m in matches if m.exposure_class]
        if not any(exposure_classes):
            recommendations.append("Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ ĞºĞ»Ğ°ÑÑÑ‹ Ğ²Ğ¾Ğ·Ğ´ĞµĞ¹ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¹ ÑÑ€ĞµĞ´Ñ‹ (XC, XF, XA Ğ¸ Ñ‚.Ğ´.)")
        
        # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼
        elements = [m.structural_element for m in matches if m.structural_element]
        if not any(elements):
            recommendations.append("Ğ£Ñ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ² ĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ…")
        
        return recommendations

    def _match_to_dict(self, match: ConcreteMatch) -> Dict[str, Any]:
        """ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ ConcreteMatch Ğ² ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ"""
        result = asdict(match)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
        grade_info = self.validator.get_grade_info(match.grade)
        if grade_info:
            result["grade_properties"] = grade_info
        
        return result

    def analyze_document(self, file_path: str) -> AnalysisResult:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚"""
        try:
            if self.doc_parser:
                text = self.doc_parser.parse(file_path)
            else:
                # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            return self.analyze_text(text, source_type="document")
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ° {file_path}: {e}")
            return AnalysisResult(
                success=False,
                total_matches=0,
                analysis_method="document_analysis_error",
                processing_time=0,
                concrete_summary=[],
                structural_elements=[],
                compliance_issues=[f"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°: {str(e)}"],
                recommendations=["ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚"],
                confidence_score=0.0
            )

    def analyze_smeta(self, file_path: str) -> AnalysisResult:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¼ĞµÑ‚Ñƒ"""
        try:
            if self.smeta_parser:
                data = self.smeta_parser.parse(file_path)
                # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ğ²ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· ÑĞ¼ĞµÑ‚Ñ‹
                text = " ".join(str(value) for value in data.values() if isinstance(value, (str, int, float)))
            else:
                # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğµ
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            return self.analyze_text(text, source_type="smeta")
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑĞ¼ĞµÑ‚Ñ‹ {file_path}: {e}")
            return AnalysisResult(
                success=False,
                total_matches=0,
                analysis_method="smeta_analysis_error", 
                processing_time=0,
                concrete_summary=[],
                structural_elements=[],
                compliance_issues=[f"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ ÑĞ¼ĞµÑ‚Ñ‹: {str(e)}"],
                recommendations=["ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ„Ğ°Ğ¹Ğ»Ğ° ÑĞ¼ĞµÑ‚Ñ‹"],
                confidence_score=0.0
            )

    def generate_report(self, result: AnalysisResult, output_path: str = None) -> Dict[str, Any]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚"""
        report = {
            "analysis_metadata": {
                "timestamp": datetime.now().isoformat(),
                "agent_version": "2.0_improved",
                "knowledge_base": self.knowledge_base_path,
                "success": result.success,
                "processing_time": result.processing_time,
                "total_matches": result.total_matches,
                "confidence_score": result.confidence_score
            },
            "concrete_analysis": {
                "method": result.analysis_method,
                "matches": result.concrete_summary,
                "unique_grades": list(set(m["grade"] for m in result.concrete_summary)),
                "grade_frequency": self._calculate_grade_frequency(result.concrete_summary)
            },
            "structural_analysis": {
                "elements": result.structural_elements,
                "element_types": list(set(e.get("type", "nespecifikovÃ¡no") for e in result.structural_elements))
            },
            "compliance_check": {
                "issues": result.compliance_issues,
                "recommendations": result.recommendations,
                "compliance_score": max(0, 1.0 - len(result.compliance_issues) * 0.2)
            },
            "statistics": {
                "avg_confidence": result.confidence_score,
                "high_confidence_matches": len([m for m in result.concrete_summary if m.get("confidence", 0) > 0.8]),
                "with_exposure_class": len([m for m in result.concrete_summary if m.get("exposure_class")]),
                "with_structural_element": len([m for m in result.concrete_summary if m.get("structural_element")])
            }
        }
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚, ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½ Ğ¿ÑƒÑ‚ÑŒ
        if output_path:
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
                logger.info(f"ĞÑ‚Ñ‡ĞµÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {output_path}")
            except Exception as e:
                logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°: {e}")
        
        return report

    def _calculate_grade_frequency(self, matches: List[Dict[str, Any]]) -> Dict[str, int]:
        """ĞŸĞ¾Ğ´ÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñƒ Ğ¼Ğ°Ñ€Ğ¾Ğº"""
        frequency = {}
        for match in matches:
            grade = match.get("grade", "unknown")
            frequency[grade] = frequency.get(grade, 0) + 1
        return frequency

    # ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ API
    def analyze(self, text: str) -> Dict[str, Any]:
        """ĞœĞµÑ‚Ğ¾Ğ´ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ API"""
        result = self.analyze_text(text)
        
        return {
            "success": result.success,
            "total_matches": result.total_matches,
            "analysis_method": result.analysis_method,
            "concrete_summary": result.concrete_summary,
            "confidence_score": result.confidence_score,
            "processing_time": result.processing_time
        }

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
import time
from datetime import datetime

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼ API
def analyze_concrete_improved(text: str, knowledge_base_path: str = None) -> Dict[str, Any]:
    """Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° - Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    if knowledge_base_path is None:
        knowledge_base_path = "knowledge_base/complete-concrete-knowledge-base.json"
    
    agent = ConcreteAgentHybrid(knowledge_base_path)
    return agent.analyze(text)

def create_concrete_agent(knowledge_base_path: str = None) -> ConcreteAgentHybrid:
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"""
    if knowledge_base_path is None:
        knowledge_base_path = "knowledge_base/complete-concrete-knowledge-base.json"
    
    return ConcreteAgentHybrid(knowledge_base_path)

if __name__ == "__main__":
    # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    test_text = """
    ZÃ¡kladovÃ¡ konstrukce bude provedena z betonu tÅ™Ã­dy C25/30 XC1, XA1.
    StÄ›novÃ© konstrukce budou z betonu C30/37 XF2.
    Pro pilÃ­Å™e se pouÅ¾ije beton LC25/28.
    
    NeplatnÃ© kÃ³dy: C425, CZ75994234, strÃ¡nka 125.
    SpoleÄnost ABC s.r.o. dodÃ¡ materiÃ¡l podle normy ÄŒSN EN 206.
    
    VÄ›nec bude betonovÃ¡n betonem tÅ™Ã­dy C20/25 s cementem CEM I 42.5 R.
    Deska garÃ¡Å¾e vyÅ¾aduje beton C30/37 XF4 kvÅ¯li zmrazovacÃ­m cyklÅ¯m.
    """
    
    print("ğŸ§± TESTOVÃNÃ VYLEPÅ ENÃ‰HO CONCRETE AGENT")
    print("=" * 60)
    
    # VytvoÅ™enÃ­ agenta
    agent = create_concrete_agent()
    
    # AnalÃ½za textu
    result = agent.analyze_text(test_text)
    
    print(f"âœ… ÃšspÄ›ch: {result.success}")
    print(f"ğŸ“Š Nalezeno marky: {result.total_matches}")
    print(f"âš¡ Doba zpracovÃ¡nÃ­: {result.processing_time:.3f}s")
    print(f"ğŸ¯ CelkovÃ¡ jistota: {result.confidence_score:.2f}")
    print()
    
    print("ğŸ” NALEZENÃ‰ MARKY:")
    for i, match in enumerate(result.concrete_summary, 1):
        print(f"{i:2d}. {match['grade']:8s} | {match['location']:15s} | {match['confidence']:.2f} | {match.get('exposure_class', 'N/A')}")
    
    print()
    print("ğŸ—ï¸ KONSTRUKÄŒNÃ PRVKY:")
    for element in result.structural_elements:
        print(f"   - {element.get('type', 'N/A')}: {element.get('requirements', ['N/A'])[0]}")
    
    print()
    print("âš ï¸ PROBLÃ‰MY A DOPORUÄŒENÃ:")
    for issue in result.compliance_issues:
        print(f"   âŒ {issue}")
    for rec in result.recommendations:
        print(f"   ğŸ’¡ {rec}")
    
    print()
    print("ğŸ“‹ GENEROVÃNÃ PODROBNÃ‰HO REPORTU...")
    
    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚
    report = agent.generate_report(result, "concrete_analysis_report.json")
    print(f"âœ… PodrobnÃ½ report uloÅ¾en jako 'concrete_analysis_report.json'")
    print(f"ğŸ“ˆ Statistiky: {report['statistics']}")
