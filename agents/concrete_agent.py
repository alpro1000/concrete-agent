"""
Hybrid Concrete Agent:
- Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· (regex + Ð¿Ð°Ñ€ÑÐµÑ€Ñ‹)
- ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ Claude Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ð¹
- Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ‡ÐµÑ€ÐµÐ· save_merged_report
"""

import re
import logging
import os
import asyncio
from typing import List, Dict, Any

from parsers.doc_parser import DocParser
from parsers.smeta_parser import SmetaParser
from parsers.xml_smeta_parser import XMLSmetaParser
from utils.claude_client import get_claude_client
from outputs.save_report import save_merged_report  # âœ… ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ JSON

logger = logging.getLogger(__name__)


class HybridConcreteAnalysisAgent:
    def __init__(self, use_claude: bool = True, claude_mode: str = "enhancement"):
        """
        Args:
            use_claude: Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð»Ð¸ Claude API
            claude_mode: "enhancement" | "primary" | "fallback"
        """
        self.use_claude = use_claude
        self.claude_mode = claude_mode
        self.claude_client = get_claude_client() if use_claude else None

        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð°Ñ€ÑÐµÑ€Ð¾Ð²
        self.doc_parser = DocParser()
        self.smeta_parser = SmetaParser()
        self.xml_parser = XMLSmetaParser()

        # ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¼Ð°Ñ€Ð¾Ðº Ð±ÐµÑ‚Ð¾Ð½Ð°
        self.concrete_patterns = [
            r'\b(C\d{1,2}/\d{1,2})\b',              
            r'\b(B\d{1,2})\b',                      
            r'(?:beton|betÃ³n)\s+([BCM]\d+(?:/\d+)?)',
            r'(?:tÅ™Ã­da|tÅ™Ã­da betonu)\s+([BCM]\d+(?:/\d+)?)'
        ]

        # ÐšÐ»Ð°ÑÑÑ‹ ÑÑ€ÐµÐ´Ñ‹ Ð¸ ÑƒÐ´Ð¾Ð±Ð¾ÑƒÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸
        self.env_classes_regex = r'\b(XO|XC[1-4]|XD[1-3]|XS[1-3]|XF[1-4]|XA[1-3])\b'
        self.workability_regex = r'\b(S[1-5])\b'

        # ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ‹ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
        self.context_patterns = {
            "zÃ¡klady": r'zÃ¡klad|foundation',
            "vÄ›nce": r'vÄ›nec|ring beam',
            "stÄ›ny": r'stÄ›na|wall',
            "sloupy": r'sloup|column',
            "deska": r'deska|slab|floor',
            "schodiÅ¡tÄ›": r'schodiÅ¡tÄ›|stair'
        }

    async def analyze_concrete(self, doc_paths: List[str], smeta_path: str) -> Dict[str, Any]:
        """ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
        logger.info(f"ðŸš€ Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð°Ð½Ð°Ð»Ð¸Ð· {len(doc_paths)} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² + {smeta_path}")

        # 1. Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
        local_analysis = await self._fast_local_analysis(doc_paths, smeta_path)

        # 2. ÐŸÑ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Claude
        if self._should_use_claude(local_analysis):
            try:
                all_text = await self._extract_all_text(doc_paths)
                smeta_data = self._parse_smeta(smeta_path)

                enhanced = await self.claude_client.enhance_analysis(local_analysis, all_text, smeta_data)

                result = self._merge_analyses(local_analysis, enhanced, timing={})
                save_merged_report(result)  # âœ… ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
                return result
            except Exception as e:
                logger.error(f"âŒ Claude Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}")

        # 3. Ð•ÑÐ»Ð¸ Claude Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ â†’ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
        save_merged_report(local_analysis)
        return local_analysis

    async def _fast_local_analysis(self, doc_paths: List[str], smeta_path: str) -> Dict[str, Any]:
        """Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
        all_text = ""
        for path in doc_paths:
            try:
                all_text += self.doc_parser.parse(path) + "\n"
            except Exception as e:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° {path}: {e}")

        smeta_data = self._parse_smeta(smeta_path)
        concrete_data = {}

        # ÐŸÐ¾Ð¸ÑÐº ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ð¹ Ð±ÐµÑ‚Ð¾Ð½Ð°
        for pattern in self.concrete_patterns:
            for match in re.finditer(pattern, all_text, re.IGNORECASE):
                grade = match.group(1) if match.groups() else match.group(0)
                grade = grade.upper().strip()
                if not grade:
                    continue

                if grade not in concrete_data:
                    concrete_data[grade] = {
                        "environment_classes": set(),
                        "workability_classes": set(),
                        "used_in": set(),
                        "smeta_mentions": []
                    }

                # Ð˜Ñ‰ÐµÐ¼ ÐºÐ»Ð°ÑÑÑ‹ ÑÑ€ÐµÐ´Ñ‹ Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
                snippet = all_text[max(0, match.start()-100): match.end()+100]

                env_classes = set(re.findall(self.env_classes_regex, snippet, re.IGNORECASE))
                concrete_data[grade]["environment_classes"].update(env_classes)

                workability = set(re.findall(self.workability_regex, snippet, re.IGNORECASE))
                concrete_data[grade]["workability_classes"].update(workability)

                for context_name, context_pattern in self.context_patterns.items():
                    if re.search(context_pattern, snippet, re.IGNORECASE):
                        concrete_data[grade]["used_in"].add(context_name)

        # ÐŸÐ¾Ð¸ÑÐº Ð² ÑÐ¼ÐµÑ‚Ðµ
        for idx, row in enumerate(smeta_data):
            row_text = " ".join(str(v) for v in row.values()).lower()
            for grade in concrete_data.keys():
                if grade.lower() in row_text:
                    concrete_data[grade]["smeta_mentions"].append({
                        "row": idx+1,
                        "description": row_text[:200]
                    })

        result = [
            {
                "grade": grade,
                "used_in": sorted(data["used_in"]),
                "environment_classes": sorted(data["environment_classes"]),
                "workability_classes": sorted(data["workability_classes"]),
                "smeta_mentions": data["smeta_mentions"]
            }
            for grade, data in concrete_data.items()
        ]

        return {
            "concrete_summary": result,
            "analysis_stats": {
                "documents_processed": len(doc_paths),
                "smeta_rows_analyzed": len(smeta_data),
                "concrete_grades_found": len(result),
                "total_text_length": len(all_text)
            }
        }

    def _parse_smeta(self, smeta_path: str):
        try:
            if smeta_path.endswith(".xml"):
                return self.xml_parser.parse(smeta_path)
            elif smeta_path.endswith((".xls", ".xlsx")):
                return self.smeta_parser.parse(smeta_path)
            return []
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¼ÐµÑ‚Ñ‹: {e}")
            return []

    async def _extract_all_text(self, doc_paths: List[str]) -> str:
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ñ Claude"""
        all_text = ""
        for path in doc_paths:
            try:
                all_text += self.doc_parser.parse(path)
            except Exception as e:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° {path}: {e}")
        return all_text[:8000]  # Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Claude

    def _should_use_claude(self, local: Dict) -> bool:
        if not self.use_claude or not self.claude_client:
            return False
        stats = local.get("analysis_stats", {})
        return stats.get("concrete_grades_found", 0) < 2  # ÐµÑÐ»Ð¸ Ð¼Ð°Ð»Ð¾ Ð½Ð°ÑˆÐ»Ð¸ â†’ Ð·Ð¾Ð²Ñ‘Ð¼ Claude

    def _merge_analyses(self, local: Dict, enhanced: Dict, timing: Dict) -> Dict:
        """Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¸ Claude Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
        return {
            "concrete_summary": enhanced.get("claude_concrete_analysis", local.get("concrete_summary", [])),
            "local_analysis": local,
            "claude_analysis": enhanced.get("claude_concrete_analysis", {}),
            "materials_analysis": enhanced.get("claude_materials_analysis", {}),
            "analysis_method": "hybrid_local_claude",
            "timing": timing
        }


# === API Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ ===
async def analyze_concrete(doc_paths: List[str], smeta_path: str, use_claude: bool = True, claude_mode: str = "enhancement") -> Dict[str, Any]:
    agent = HybridConcreteAnalysisAgent(use_claude=use_claude, claude_mode=claude_mode)
    return await agent.analyze_concrete(doc_paths, smeta_path)


def analyze_concrete_sync(doc_paths: List[str], smeta_path: str, use_claude: bool = True, claude_mode: str = "enhancement") -> Dict[str, Any]:
    return asyncio.run(analyze_concrete(doc_paths, smeta_path, use_claude, claude_mode))
