"""
Nanonets Integration
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Nanonets API
"""

import requests
import logging
from pathlib import Path
from typing import Optional, Dict, Any
import json
import mimetypes

logger = logging.getLogger(__name__)


class NanonetsProcessor:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ Nanonets API
    
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
    - –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω—É–∂–Ω–∞ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ (—Å–∫–∞–Ω vs searchable)
    - –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Nanonets
    - –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç/—Ç–∞–±–ª–∏—Ü—ã
    - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    """
    
    NANONETS_API_URL = "https://extraction-api.nanonets.com/extract"
    
    # –§–æ—Ä–º–∞—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –ù–£–ñ–ù–û –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
    PROCESSABLE_FORMATS = {
        '.pdf',      # PDF (–ª—é–±—ã–µ - –ø—Ä–æ–≤–µ—Ä–∏–º searchable)
        '.png',      # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        '.jpg',
        '.jpeg',
        '.tiff',
        '.bmp'
    }
    
    # –§–æ—Ä–º–∞—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –ù–£–ñ–ù–û –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
    SKIP_FORMATS = {
        '.json',     # –£–∂–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
        '.csv',
        '.xlsx',
        '.xls',
        '.txt',
        '.md',
        '.docx'      # Word –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –¥—Ä—É–≥–∏–º–∏ —Å—Ä–µ–¥—Å—Ç–≤–∞–º–∏
    }
    
    def __init__(self, api_key: str):
        """
        Args:
            api_key: Nanonets API key (–∏–∑ environment variables)
        """
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}"
        }
    
    def should_process(self, file_path: Path) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª —á–µ—Ä–µ–∑ Nanonets
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            True –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞, False –µ—Å–ª–∏ –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
        """
        ext = file_path.suffix.lower()
        
        # –¢–æ—á–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if ext in self.SKIP_FORMATS:
            logger.info(f"‚è© Skipping {file_path.name} - format doesn't need processing")
            return False
        
        # –¢–æ—á–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        if ext in self.PROCESSABLE_FORMATS:
            # –î–ª—è PDF - –ø—Ä–æ–≤–µ—Ä–∏–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–Ω —Å–∫–∞–Ω–æ–º
            if ext == '.pdf':
                is_scan = self._is_pdf_scan(file_path)
                if is_scan:
                    logger.info(f"üìÑ {file_path.name} is a scan - needs OCR")
                    return True
                else:
                    logger.info(f"‚úÖ {file_path.name} is searchable - no OCR needed")
                    return False
            
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) - –≤—Å–µ–≥–¥–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            return True
        
        # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        logger.warning(f"‚ö†Ô∏è Unknown format: {ext} for {file_path.name}")
        return False
    
    def _is_pdf_scan(self, pdf_path: Path) -> bool:
        """
        –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —è–≤–ª—è–µ—Ç—Å—è –ª–∏ PDF —Å–∫–∞–Ω–æ–º
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É:
        - –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç
        - –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ/–Ω–µ—Ç ‚Üí —Å–∫–∞–Ω
        """
        try:
            import pdfplumber
            
            with pdfplumber.open(pdf_path) as pdf:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                text_length = 0
                for i, page in enumerate(pdf.pages[:3]):
                    text = page.extract_text() or ""
                    text_length += len(text.strip())
                
                # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Å–∫–∞–Ω
                return text_length < 100
        
        except ImportError:
            logger.warning("pdfplumber not installed, assuming PDF is scan")
            return True
        except Exception as e:
            logger.error(f"Error checking PDF: {e}")
            return True  # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–±—Ä–∞–±–æ—Ç–∞–µ–º
    
    def process_file(
        self, 
        file_path: Path,
        output_type: str = "markdown"
    ) -> Optional[Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —á–µ—Ä–µ–∑ Nanonets API
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            output_type: markdown, json, –∏–ª–∏ text
            
        Returns:
            {
                "content": "...",       # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                "format": "markdown",   # –§–æ—Ä–º–∞—Ç
                "metadata": {...}       # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç Nanonets
            }
            –ò–ª–∏ None –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å
        """
        
        if not self.should_process(file_path):
            return None
        
        logger.info(f"ü§ñ Processing {file_path.name} with Nanonets...")
        
        try:
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª
            with open(file_path, 'rb') as f:
                files = {"file": f}
                data = {"output_type": output_type}
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Nanonets
                response = requests.post(
                    self.NANONETS_API_URL,
                    headers=self.headers,
                    files=files,
                    data=data,
                    timeout=300  # 5 –º–∏–Ω—É—Ç –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
                )
            
            if response.status_code == 200:
                result = response.json()
                
                logger.info(f"‚úÖ Successfully processed {file_path.name}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
                content = self._extract_content(result, output_type)
                
                return {
                    "content": content,
                    "format": output_type,
                    "metadata": result.get("metadata", {}),
                    "original_file": file_path.name
                }
            
            else:
                logger.error(
                    f"‚ùå Nanonets API error for {file_path.name}: "
                    f"{response.status_code} - {response.text}"
                )
                return None
        
        except requests.exceptions.Timeout:
            logger.error(f"‚è∞ Timeout processing {file_path.name}")
            return None
        
        except Exception as e:
            logger.error(f"‚ùå Error processing {file_path.name}: {e}")
            return None
    
    def _extract_content(self, result: Dict, output_type: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ Nanonets"""
        
        if output_type == "markdown":
            return result.get("markdown", "")
        
        elif output_type == "json":
            return json.dumps(result.get("data", {}), indent=2, ensure_ascii=False)
        
        elif output_type == "text":
            return result.get("text", "")
        
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—ë –∫–∞–∫ JSON
            return json.dumps(result, indent=2, ensure_ascii=False)
    
    def process_and_save(
        self,
        file_path: Path,
        output_dir: Optional[Path] = None
    ) -> Optional[Path]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä—è–¥–æ–º
        
        Args:
            file_path: –ü—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É
            output_dir: –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Ä—è–¥–æ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º)
            
        Returns:
            –ü—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
            
        Example:
            input:  B2_csn_standards/CSN_EN_1992.pdf (—Å–∫–∞–Ω)
            output: B2_csn_standards/CSN_EN_1992_processed.json
        """
        
        result = self.process_file(file_path, output_type="json")
        
        if not result:
            return None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        output_dir = output_dir or file_path.parent
        output_name = f"{file_path.stem}_processed.json"
        output_path = output_dir / output_name
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(result["content"])
            
            logger.info(f"üíæ Saved processed file: {output_path}")
            return output_path
        
        except Exception as e:
            logger.error(f"‚ùå Error saving processed file: {e}")
            return None
    
    def batch_process_directory(
        self,
        directory: Path,
        recursive: bool = True
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        
        Args:
            directory: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ
            recursive: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –ø–∞–ø–∫–∏
            
        Returns:
            {
                "processed": 5,
                "skipped": 10,
                "failed": 1,
                "files": [...]
            }
        """
        
        logger.info(f"üîÑ Batch processing directory: {directory}")
        
        stats = {
            "processed": 0,
            "skipped": 0,
            "failed": 0,
            "files": []
        }
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        if recursive:
            files = list(directory.rglob("*"))
        else:
            files = list(directory.glob("*"))
        
        files = [f for f in files if f.is_file()]
        
        logger.info(f"üìä Found {len(files)} files")
        
        for file_path in files:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            if "_processed" in file_path.stem:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ
            if file_path.name in ["metadata.json", ".gitkeep"]:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
            if not self.should_process(file_path):
                stats["skipped"] += 1
                continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            output_path = self.process_and_save(file_path)
            
            if output_path:
                stats["processed"] += 1
                stats["files"].append({
                    "original": str(file_path),
                    "processed": str(output_path)
                })
            else:
                stats["failed"] += 1
        
        logger.info(
            f"‚úÖ Batch processing complete: "
            f"{stats['processed']} processed, "
            f"{stats['skipped']} skipped, "
            f"{stats['failed']} failed"
        )
        
        return stats


# === –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï ===

def example_usage():
    """–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    
    from app.core.config import settings
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = NanonetsProcessor(
        api_key=settings.NANONETS_API_KEY
    )
    
    # 1. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª
    result = processor.process_file(
        Path("app/knowledge_base/B2_csn_standards/CSN_EN_1992.pdf")
    )
    
    if result:
        print("Extracted content:", result["content"][:500])
    
    # 2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
    output_path = processor.process_and_save(
        Path("app/knowledge_base/B2_csn_standards/CSN_EN_1992.pdf")
    )
    
    if output_path:
        print(f"Saved to: {output_path}")
    
    # 3. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å—é –ø–∞–ø–∫—É
    stats = processor.batch_process_directory(
        Path("app/knowledge_base/B2_csn_standards"),
        recursive=True
    )
    
    print(f"Processed {stats['processed']} files")


if __name__ == "__main__":
    example_usage()
